{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import os\n",
    "import re\n",
    "from rdkit.Chem import rdchem\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0,'/global/homes/b/bpb/repos/blink')\n",
    "import blink\n",
    "sys.path.insert(0,'/global/homes/b/bpb/repos/scndb/')\n",
    "import scndb.tools as wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/public_and_internal_files_with_massive_and_redu.tsv', sep='\\t')\n",
    "# out_dir = '/global/cfs/cdirs/metatlas/projects/carbon_network/raw_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_extension</th>\n",
       "      <th>h5</th>\n",
       "      <th>buddy</th>\n",
       "      <th>data_dir</th>\n",
       "      <th>massive_id</th>\n",
       "      <th>h5_basename</th>\n",
       "      <th>no_extension_basename</th>\n",
       "      <th>redu_filename</th>\n",
       "      <th>title</th>\n",
       "      <th>dataset</th>\n",
       "      <th>...</th>\n",
       "      <th>DataSource</th>\n",
       "      <th>in_redu_plant</th>\n",
       "      <th>in_massive_dom_list</th>\n",
       "      <th>num_unique_spectra</th>\n",
       "      <th>num_unique_formula</th>\n",
       "      <th>row_count</th>\n",
       "      <th>hash_value</th>\n",
       "      <th>fraction_within_half_tolerance</th>\n",
       "      <th>total_formula</th>\n",
       "      <th>good_formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...</td>\n",
       "      <td>Exometabolomics of Switchgrass rhizosphere</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>456</td>\n",
       "      <td>4543026168108574362794479450808782822576102481...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...</td>\n",
       "      <td>Exometabolomics of Switchgrass rhizosphere</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>456</td>\n",
       "      <td>1146699731202151078167183871657244067319867200...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...</td>\n",
       "      <td>Exometabolomics of Switchgrass rhizosphere</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>456</td>\n",
       "      <td>6050222582699240527582470064019762021131872133...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...</td>\n",
       "      <td>Exometabolomics of Switchgrass rhizosphere</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>456</td>\n",
       "      <td>3702313854198524301531740173462475658596229137...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...</td>\n",
       "      <td>Exometabolomics of Switchgrass rhizosphere</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>456</td>\n",
       "      <td>3204540641109984802875185148711391962459030977...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8629</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>FRCgw2_20230830</td>\n",
       "      <td>20230831_EB_MdR_101544-059_FRCgw2_20230830_EXP...</td>\n",
       "      <td>20230831_EB_MdR_101544-059_FRCgw2_20230830_EXP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>258</td>\n",
       "      <td>2</td>\n",
       "      <td>7691554974928442192395477242826347171018227719...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8630</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>OMTSoil50g_Pilot</td>\n",
       "      <td>20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...</td>\n",
       "      <td>20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>740</td>\n",
       "      <td>642</td>\n",
       "      <td>2</td>\n",
       "      <td>2594972266128828903000352158747002890197414379...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>740</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8631</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>OMTSoil50g_Pilot</td>\n",
       "      <td>20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...</td>\n",
       "      <td>20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>728</td>\n",
       "      <td>640</td>\n",
       "      <td>2</td>\n",
       "      <td>4209636828858950554459278668184188604433847647...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>728</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8632</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>CenturyExpPilot_20230414</td>\n",
       "      <td>20230919_EB_SMK_107002-011_CenturyExpPilot_202...</td>\n",
       "      <td>20230919_EB_SMK_107002-011_CenturyExpPilot_202...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>585</td>\n",
       "      <td>493</td>\n",
       "      <td>1</td>\n",
       "      <td>1088936055166875952807734893139980155519399625...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8633</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>DOM-TargetedMS2_pilot1</td>\n",
       "      <td>20231005_JGI_TH_Internal_DOM-TargetedMS2_pilot...</td>\n",
       "      <td>20231005_JGI_TH_Internal_DOM-TargetedMS2_pilot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>194</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>9739618844316565703298755352775119576894402083...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2258 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           no_extension  \\\n",
       "0     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "1     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "2     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "3     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "4     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "...                                                 ...   \n",
       "8629  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8630  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8631  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8632  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8633  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "\n",
       "                                                     h5  \\\n",
       "0     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "1     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "2     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "3     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "4     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "...                                                 ...   \n",
       "8629  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8630  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8631  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8632  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8633  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "\n",
       "                                                  buddy  \\\n",
       "0     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "1     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "2     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "3     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "4     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "...                                                 ...   \n",
       "8629  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8630  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8631  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8632  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8633  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "\n",
       "                                               data_dir  \\\n",
       "0                            /pscratch/sd/b/bpb/massive   \n",
       "1                            /pscratch/sd/b/bpb/massive   \n",
       "2                            /pscratch/sd/b/bpb/massive   \n",
       "3                            /pscratch/sd/b/bpb/massive   \n",
       "4                            /pscratch/sd/b/bpb/massive   \n",
       "...                                                 ...   \n",
       "8629  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8630  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8631  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8632  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8633  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "\n",
       "                    massive_id  \\\n",
       "0                 MSV000088543   \n",
       "1                 MSV000088543   \n",
       "2                 MSV000088543   \n",
       "3                 MSV000088543   \n",
       "4                 MSV000088543   \n",
       "...                        ...   \n",
       "8629           FRCgw2_20230830   \n",
       "8630          OMTSoil50g_Pilot   \n",
       "8631          OMTSoil50g_Pilot   \n",
       "8632  CenturyExpPilot_20230414   \n",
       "8633    DOM-TargetedMS2_pilot1   \n",
       "\n",
       "                                            h5_basename  \\\n",
       "0     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "1     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "2     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "3     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "4     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "...                                                 ...   \n",
       "8629  20230831_EB_MdR_101544-059_FRCgw2_20230830_EXP...   \n",
       "8630  20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...   \n",
       "8631  20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...   \n",
       "8632  20230919_EB_SMK_107002-011_CenturyExpPilot_202...   \n",
       "8633  20231005_JGI_TH_Internal_DOM-TargetedMS2_pilot...   \n",
       "\n",
       "                                  no_extension_basename  \\\n",
       "0     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "1     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "2     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "3     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "4     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "...                                                 ...   \n",
       "8629  20230831_EB_MdR_101544-059_FRCgw2_20230830_EXP...   \n",
       "8630  20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...   \n",
       "8631  20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...   \n",
       "8632  20230919_EB_SMK_107002-011_CenturyExpPilot_202...   \n",
       "8633  20231005_JGI_TH_Internal_DOM-TargetedMS2_pilot...   \n",
       "\n",
       "                                          redu_filename  \\\n",
       "0     f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...   \n",
       "1     f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...   \n",
       "2     f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...   \n",
       "3     f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...   \n",
       "4     f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...   \n",
       "...                                                 ...   \n",
       "8629                                                NaN   \n",
       "8630                                                NaN   \n",
       "8631                                                NaN   \n",
       "8632                                                NaN   \n",
       "8633                                                NaN   \n",
       "\n",
       "                                           title       dataset  ...  \\\n",
       "0     Exometabolomics of Switchgrass rhizosphere  MSV000088543  ...   \n",
       "1     Exometabolomics of Switchgrass rhizosphere  MSV000088543  ...   \n",
       "2     Exometabolomics of Switchgrass rhizosphere  MSV000088543  ...   \n",
       "3     Exometabolomics of Switchgrass rhizosphere  MSV000088543  ...   \n",
       "4     Exometabolomics of Switchgrass rhizosphere  MSV000088543  ...   \n",
       "...                                          ...           ...  ...   \n",
       "8629                                         NaN           NaN  ...   \n",
       "8630                                         NaN           NaN  ...   \n",
       "8631                                         NaN           NaN  ...   \n",
       "8632                                         NaN           NaN  ...   \n",
       "8633                                         NaN           NaN  ...   \n",
       "\n",
       "     DataSource in_redu_plant in_massive_dom_list  num_unique_spectra  \\\n",
       "0           NaN         False                True                  34   \n",
       "1           NaN         False                True                  32   \n",
       "2           NaN         False                True                  36   \n",
       "3           NaN         False                True                  43   \n",
       "4           NaN         False                True                  41   \n",
       "...         ...           ...                 ...                 ...   \n",
       "8629        NaN         False               False                 311   \n",
       "8630        NaN         False               False                 740   \n",
       "8631        NaN         False               False                 728   \n",
       "8632        NaN         False               False                 585   \n",
       "8633        NaN         False               False                 194   \n",
       "\n",
       "     num_unique_formula row_count  \\\n",
       "0                    30       456   \n",
       "1                    29       456   \n",
       "2                    34       456   \n",
       "3                    40       456   \n",
       "4                    38       456   \n",
       "...                 ...       ...   \n",
       "8629                258         2   \n",
       "8630                642         2   \n",
       "8631                640         2   \n",
       "8632                493         1   \n",
       "8633                159         1   \n",
       "\n",
       "                                             hash_value  \\\n",
       "0     4543026168108574362794479450808782822576102481...   \n",
       "1     1146699731202151078167183871657244067319867200...   \n",
       "2     6050222582699240527582470064019762021131872133...   \n",
       "3     3702313854198524301531740173462475658596229137...   \n",
       "4     3204540641109984802875185148711391962459030977...   \n",
       "...                                                 ...   \n",
       "8629  7691554974928442192395477242826347171018227719...   \n",
       "8630  2594972266128828903000352158747002890197414379...   \n",
       "8631  4209636828858950554459278668184188604433847647...   \n",
       "8632  1088936055166875952807734893139980155519399625...   \n",
       "8633  9739618844316565703298755352775119576894402083...   \n",
       "\n",
       "     fraction_within_half_tolerance total_formula  good_formula  \n",
       "0                               1.0            34            34  \n",
       "1                               1.0            32            32  \n",
       "2                               1.0            36            36  \n",
       "3                               1.0            43            43  \n",
       "4                               1.0            41            41  \n",
       "...                             ...           ...           ...  \n",
       "8629                            1.0           311           311  \n",
       "8630                            1.0           740           740  \n",
       "8631                            1.0           728           728  \n",
       "8632                            1.0           585           585  \n",
       "8633                            1.0           194           194  \n",
       "\n",
       "[2258 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/global/cfs/cdirs/metatlas/projects/carbon_network/public_and_internal_files_with_massive_and_redu.tsv', sep='\\t')\n",
    "df = df[~df['buddy'].str.contains('qc',case=False)]\n",
    "df = df[~df['buddy'].str.contains('blank',case=False)]\n",
    "# df['keywords'] = df['keywords'].apply(lambda x: x.split('###') if type(x)==str else [])\n",
    "# df['keyword_DOM'] = df['keywords'].apply(lambda x: True if (('dom' in x) | ('organic matter' in x) | ('soil' in x)) else False)\n",
    "idx1 = (df['in_massive_dom_list'])# | df['keyword_DOM']\n",
    "# idx2 = df['data_dir']=='/global/cfs/cdirs/metatlas/projects/massive_data_for_scn'\n",
    "idx3 = df['buddy'].str.contains('rawdata_for_scn')\n",
    "# df = df[(idx3)]# | (idx1)] #  | (idx2)\n",
    "df = df[(idx3) | (idx1)] #  | (idx2)\n",
    "# df = df[df['SampleType']=='plant']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# out_dir = '/global/cfs/cdirs/metatlas/projects/carbon_network/raw_data'\n",
    "# for i,row in df.iterrows():\n",
    "#     f = row['no_extension']\n",
    "#     all_files = glob.glob('%s.*'%f)\n",
    "#     for file in all_files:\n",
    "#         # Define destination file path\n",
    "#         sub_dir = os.path.dirname(file)\n",
    "#         sub_dir = '%s%s'%(out_dir,sub_dir)\n",
    "#         dst_file = os.path.join(sub_dir, os.path.basename(file))\n",
    "#         if not os.path.isfile(dst_file):\n",
    "#             os.makedirs(sub_dir, exist_ok=True)\n",
    "#             # Copy the file\n",
    "#             shutil.copy2(file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# out_dir = '/global/cfs/cdirs/metatlas/projects/carbon_network/raw_data/'\n",
    "# command = ' '.join([\"find\", \"/global/cfs/cdirs/metatlas/projects/carbon_network/raw_data/\", \"-type\", \"f\", \"-name\", \"*.mzML\"])\n",
    "# result = subprocess.check_output(command, shell=True)\n",
    "\n",
    "# # Print the output\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # main_dir = '/pscratch/sd/b/bpb/massive'\n",
    "# main_dir = '/global/cfs/cdirs/metatlas/projects/rawdata_for_scn'\n",
    "\n",
    "\n",
    "# mzml_files = glob.glob(main_dir + '/**/*.mzML', recursive=True)\n",
    "# hdf5_files = glob.glob(main_dir + '/**/*.h5', recursive=True)\n",
    "# buddy_mdm_files = glob.glob(main_dir + '/**/*.parquet', recursive=True)\n",
    "\n",
    "# main_dir = '/global/cfs/cdirs/metatlas/projects/massive_data_for_scn'\n",
    "\n",
    "\n",
    "# mzml_files2 = glob.glob(main_dir + '/**/*.mzML', recursive=True)\n",
    "# hdf5_files2 = glob.glob(main_dir + '/**/*.h5', recursive=True)\n",
    "# buddy_mdm_files2 = glob.glob(main_dir + '/**/*.parquet', recursive=True)\n",
    "# mzml_files = mzml_files + mzml_files2\n",
    "# hdf5_files = hdf5_files + hdf5_files2\n",
    "# buddy_mdm_files = buddy_mdm_files + buddy_mdm_files2\n",
    "\n",
    "# # df = pd.DataFrame({'mzml': mzml_files})\n",
    "# df = pd.DataFrame({'h5': hdf5_files})\n",
    "# df['mzml'] = df['h5'].apply(lambda x: x.replace('.h5', '.mzML'))\n",
    "\n",
    "# # df['h5'] = df['mzml'].apply(lambda x: x.replace('.mzML', '.h5'))\n",
    "# df['buddy'] = df['mzml'].apply(lambda x: x.replace('.mzML', '.parquet'))\n",
    "# df['h5_completed'] = df['h5'].apply(lambda x: os.path.exists(x))\n",
    "# df['buddy_completed'] = df['buddy'].apply(lambda x: os.path.exists(x))\n",
    "# df['h5_failed'] = df['h5'].apply(lambda x: os.path.exists('%s-failed'%x))\n",
    "# df['buddy_failed'] = df['buddy'].apply(lambda x: os.path.exists('%s-failed'%x))\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment_type\n",
      "extraction_solvent\n",
      "ppl_extracted\n",
      "instrument_type\n",
      "mass_range\n",
      "doi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>environment_type:aquatic</th>\n",
       "      <th>environment_type:soil</th>\n",
       "      <th>environment_type:wetland</th>\n",
       "      <th>extraction_solvent:chloroform</th>\n",
       "      <th>extraction_solvent:methanol-water</th>\n",
       "      <th>extraction_solvent:water</th>\n",
       "      <th>ppl_extracted:False</th>\n",
       "      <th>ppl_extracted:True</th>\n",
       "      <th>instrument_type:12 Tesla FT-ICR-MS</th>\n",
       "      <th>instrument_type:15 Tesla FT-ICR-MS</th>\n",
       "      <th>mass_range:100-900</th>\n",
       "      <th>mass_range:125-2000</th>\n",
       "      <th>mass_range:150-2000</th>\n",
       "      <th>mass_range:200-1200</th>\n",
       "      <th>doi:https://doi.org/10.1016/j.gca.2021.10.018</th>\n",
       "      <th>doi:https://doi.org/10.1038/s41467-018-05665-9</th>\n",
       "      <th>doi:https://doi.org/10.1371/journal.pone.0119188</th>\n",
       "      <th>doi:https://doi.org/10.5194/bg-16-3911-2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C6H5NO4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C6H4O5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C6H6O5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C6H8O5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C10H8O2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15783</th>\n",
       "      <td>C20H19N1O11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15784</th>\n",
       "      <td>C19H19N1O12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15785</th>\n",
       "      <td>C20H19N1O12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15786</th>\n",
       "      <td>C28H22O17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15787</th>\n",
       "      <td>C28H26O19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15788 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           formula  environment_type:aquatic  environment_type:soil  \\\n",
       "0          C6H5NO4                         1                      0   \n",
       "1           C6H4O5                         1                      0   \n",
       "2           C6H6O5                         1                      0   \n",
       "3           C6H8O5                         1                      0   \n",
       "4          C10H8O2                         1                      0   \n",
       "...            ...                       ...                    ...   \n",
       "15783  C20H19N1O11                         0                      1   \n",
       "15784  C19H19N1O12                         0                      1   \n",
       "15785  C20H19N1O12                         0                      1   \n",
       "15786    C28H22O17                         0                      1   \n",
       "15787    C28H26O19                         0                      1   \n",
       "\n",
       "       environment_type:wetland  extraction_solvent:chloroform  \\\n",
       "0                             0                              0   \n",
       "1                             0                              0   \n",
       "2                             0                              0   \n",
       "3                             0                              0   \n",
       "4                             0                              0   \n",
       "...                         ...                            ...   \n",
       "15783                         0                              0   \n",
       "15784                         0                              0   \n",
       "15785                         0                              0   \n",
       "15786                         0                              0   \n",
       "15787                         0                              0   \n",
       "\n",
       "       extraction_solvent:methanol-water  extraction_solvent:water  \\\n",
       "0                                      1                         0   \n",
       "1                                      1                         0   \n",
       "2                                      1                         0   \n",
       "3                                      1                         0   \n",
       "4                                      1                         0   \n",
       "...                                  ...                       ...   \n",
       "15783                                  1                         0   \n",
       "15784                                  1                         0   \n",
       "15785                                  1                         0   \n",
       "15786                                  1                         0   \n",
       "15787                                  1                         0   \n",
       "\n",
       "       ppl_extracted:False  ppl_extracted:True  \\\n",
       "0                        0                   1   \n",
       "1                        0                   1   \n",
       "2                        0                   1   \n",
       "3                        0                   1   \n",
       "4                        0                   1   \n",
       "...                    ...                 ...   \n",
       "15783                    0                   1   \n",
       "15784                    0                   1   \n",
       "15785                    0                   1   \n",
       "15786                    0                   1   \n",
       "15787                    0                   1   \n",
       "\n",
       "       instrument_type:12 Tesla FT-ICR-MS  instrument_type:15 Tesla FT-ICR-MS  \\\n",
       "0                                       0                                   1   \n",
       "1                                       0                                   1   \n",
       "2                                       0                                   1   \n",
       "3                                       0                                   1   \n",
       "4                                       0                                   1   \n",
       "...                                   ...                                 ...   \n",
       "15783                                   0                                   1   \n",
       "15784                                   0                                   1   \n",
       "15785                                   0                                   1   \n",
       "15786                                   0                                   1   \n",
       "15787                                   0                                   1   \n",
       "\n",
       "       mass_range:100-900  mass_range:125-2000  mass_range:150-2000  \\\n",
       "0                       0                    1                    0   \n",
       "1                       0                    1                    0   \n",
       "2                       0                    1                    0   \n",
       "3                       0                    1                    0   \n",
       "4                       0                    1                    0   \n",
       "...                   ...                  ...                  ...   \n",
       "15783                   0                    0                    1   \n",
       "15784                   0                    0                    1   \n",
       "15785                   0                    0                    1   \n",
       "15786                   0                    0                    1   \n",
       "15787                   0                    0                    1   \n",
       "\n",
       "       mass_range:200-1200  doi:https://doi.org/10.1016/j.gca.2021.10.018  \\\n",
       "0                        0                                              0   \n",
       "1                        0                                              0   \n",
       "2                        0                                              0   \n",
       "3                        0                                              0   \n",
       "4                        0                                              0   \n",
       "...                    ...                                            ...   \n",
       "15783                    0                                              0   \n",
       "15784                    0                                              0   \n",
       "15785                    0                                              0   \n",
       "15786                    0                                              0   \n",
       "15787                    0                                              0   \n",
       "\n",
       "       doi:https://doi.org/10.1038/s41467-018-05665-9  \\\n",
       "0                                                   1   \n",
       "1                                                   1   \n",
       "2                                                   1   \n",
       "3                                                   1   \n",
       "4                                                   1   \n",
       "...                                               ...   \n",
       "15783                                               0   \n",
       "15784                                               0   \n",
       "15785                                               0   \n",
       "15786                                               0   \n",
       "15787                                               0   \n",
       "\n",
       "       doi:https://doi.org/10.1371/journal.pone.0119188  \\\n",
       "0                                                     0   \n",
       "1                                                     0   \n",
       "2                                                     0   \n",
       "3                                                     0   \n",
       "4                                                     0   \n",
       "...                                                 ...   \n",
       "15783                                                 1   \n",
       "15784                                                 1   \n",
       "15785                                                 1   \n",
       "15786                                                 1   \n",
       "15787                                                 1   \n",
       "\n",
       "       doi:https://doi.org/10.5194/bg-16-3911-2019  \n",
       "0                                                0  \n",
       "1                                                0  \n",
       "2                                                0  \n",
       "3                                                0  \n",
       "4                                                0  \n",
       "...                                            ...  \n",
       "15783                                            0  \n",
       "15784                                            0  \n",
       "15785                                            0  \n",
       "15786                                            0  \n",
       "15787                                            0  \n",
       "\n",
       "[15788 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula_df = pd.read_csv('/global/homes/b/bpb/repos/scndb/data/merged_fticr_formula (2).csv')\n",
    "formula_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# Add new columns for each unique value in \"environment type\"\n",
    "# cols = ['formula','environment_type']\n",
    "# formula_df = pd.pivot_table(formula_df[cols], index='formula', columns='environment_type', aggfunc=lambda x: True, fill_value=False)\n",
    "cols =  ['environment_type', 'extraction_solvent',\n",
    "       'ppl_extracted', 'instrument_type',\n",
    "       'mass_range', 'doi']\n",
    "for c in cols:\n",
    "    env = formula_df.groupby(['formula',c])['polarity'].count().unstack().fillna(0)\n",
    "    env[env>0] = 1\n",
    "    env.columns = ['%s:%s'%(c,x) for x in env.columns]\n",
    "    env = env.astype(int)\n",
    "    formula_df = formula_df.merge(env, left_on='formula', right_index=True)\n",
    "    formula_df.drop(columns=c, inplace=True)\n",
    "    print(c)\n",
    "formula_df.drop_duplicates(subset='formula', inplace=True)\n",
    "formula_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "formula_df.drop(columns=['mz','ionization_method','polarity'],inplace=True)\n",
    "\n",
    "formula_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['buddy_completed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_info = pd.read_csv('../data/all_sampleinformation.tsv', sep='\\t')\n",
    "# sample_info.head()\n",
    "# sample_info['basename'] = sample_info['filename'].apply(lambda x: os.path.basename(x))\n",
    "# df['basename'] = df['mzml'].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "# df = pd.merge(df,sample_info, left_on='basename', right_on='basename',how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1074968, 14)\n",
      "(1074968, 54)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_extension</th>\n",
       "      <th>h5</th>\n",
       "      <th>buddy</th>\n",
       "      <th>data_dir</th>\n",
       "      <th>massive_id</th>\n",
       "      <th>h5_basename</th>\n",
       "      <th>no_extension_basename</th>\n",
       "      <th>redu_filename</th>\n",
       "      <th>title</th>\n",
       "      <th>dataset</th>\n",
       "      <th>...</th>\n",
       "      <th>DataSource</th>\n",
       "      <th>in_redu_plant</th>\n",
       "      <th>in_massive_dom_list</th>\n",
       "      <th>num_unique_spectra</th>\n",
       "      <th>num_unique_formula</th>\n",
       "      <th>row_count</th>\n",
       "      <th>hash_value</th>\n",
       "      <th>fraction_within_half_tolerance</th>\n",
       "      <th>total_formula</th>\n",
       "      <th>good_formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...</td>\n",
       "      <td>Exometabolomics of Switchgrass rhizosphere</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>456</td>\n",
       "      <td>4543026168108574362794479450808782822576102481...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...</td>\n",
       "      <td>Exometabolomics of Switchgrass rhizosphere</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>456</td>\n",
       "      <td>1146699731202151078167183871657244067319867200...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...</td>\n",
       "      <td>Exometabolomics of Switchgrass rhizosphere</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>456</td>\n",
       "      <td>6050222582699240527582470064019762021131872133...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...</td>\n",
       "      <td>Exometabolomics of Switchgrass rhizosphere</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>456</td>\n",
       "      <td>3702313854198524301531740173462475658596229137...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...</td>\n",
       "      <td>/pscratch/sd/b/bpb/massive</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...</td>\n",
       "      <td>f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...</td>\n",
       "      <td>Exometabolomics of Switchgrass rhizosphere</td>\n",
       "      <td>MSV000088543</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>456</td>\n",
       "      <td>3204540641109984802875185148711391962459030977...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8629</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>FRCgw2_20230830</td>\n",
       "      <td>20230831_EB_MdR_101544-059_FRCgw2_20230830_EXP...</td>\n",
       "      <td>20230831_EB_MdR_101544-059_FRCgw2_20230830_EXP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>258</td>\n",
       "      <td>2</td>\n",
       "      <td>7691554974928442192395477242826347171018227719...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>311</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8630</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>OMTSoil50g_Pilot</td>\n",
       "      <td>20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...</td>\n",
       "      <td>20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>740</td>\n",
       "      <td>642</td>\n",
       "      <td>2</td>\n",
       "      <td>2594972266128828903000352158747002890197414379...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>740</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8631</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>OMTSoil50g_Pilot</td>\n",
       "      <td>20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...</td>\n",
       "      <td>20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>728</td>\n",
       "      <td>640</td>\n",
       "      <td>2</td>\n",
       "      <td>4209636828858950554459278668184188604433847647...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>728</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8632</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>CenturyExpPilot_20230414</td>\n",
       "      <td>20230919_EB_SMK_107002-011_CenturyExpPilot_202...</td>\n",
       "      <td>20230919_EB_SMK_107002-011_CenturyExpPilot_202...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>585</td>\n",
       "      <td>493</td>\n",
       "      <td>1</td>\n",
       "      <td>1088936055166875952807734893139980155519399625...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8633</th>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>/global/cfs/cdirs/metatlas/projects/carbon_net...</td>\n",
       "      <td>DOM-TargetedMS2_pilot1</td>\n",
       "      <td>20231005_JGI_TH_Internal_DOM-TargetedMS2_pilot...</td>\n",
       "      <td>20231005_JGI_TH_Internal_DOM-TargetedMS2_pilot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>194</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>9739618844316565703298755352775119576894402083...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2258 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           no_extension  \\\n",
       "0     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "1     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "2     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "3     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "4     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "...                                                 ...   \n",
       "8629  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8630  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8631  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8632  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8633  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "\n",
       "                                                     h5  \\\n",
       "0     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "1     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "2     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "3     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "4     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "...                                                 ...   \n",
       "8629  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8630  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8631  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8632  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8633  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "\n",
       "                                                  buddy  \\\n",
       "0     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "1     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "2     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "3     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "4     /pscratch/sd/b/bpb/massive/v01/MSV000088543/cc...   \n",
       "...                                                 ...   \n",
       "8629  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8630  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8631  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8632  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8633  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "\n",
       "                                               data_dir  \\\n",
       "0                            /pscratch/sd/b/bpb/massive   \n",
       "1                            /pscratch/sd/b/bpb/massive   \n",
       "2                            /pscratch/sd/b/bpb/massive   \n",
       "3                            /pscratch/sd/b/bpb/massive   \n",
       "4                            /pscratch/sd/b/bpb/massive   \n",
       "...                                                 ...   \n",
       "8629  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8630  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8631  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8632  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "8633  /global/cfs/cdirs/metatlas/projects/carbon_net...   \n",
       "\n",
       "                    massive_id  \\\n",
       "0                 MSV000088543   \n",
       "1                 MSV000088543   \n",
       "2                 MSV000088543   \n",
       "3                 MSV000088543   \n",
       "4                 MSV000088543   \n",
       "...                        ...   \n",
       "8629           FRCgw2_20230830   \n",
       "8630          OMTSoil50g_Pilot   \n",
       "8631          OMTSoil50g_Pilot   \n",
       "8632  CenturyExpPilot_20230414   \n",
       "8633    DOM-TargetedMS2_pilot1   \n",
       "\n",
       "                                            h5_basename  \\\n",
       "0     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "1     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "2     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "3     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "4     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "...                                                 ...   \n",
       "8629  20230831_EB_MdR_101544-059_FRCgw2_20230830_EXP...   \n",
       "8630  20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...   \n",
       "8631  20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...   \n",
       "8632  20230919_EB_SMK_107002-011_CenturyExpPilot_202...   \n",
       "8633  20231005_JGI_TH_Internal_DOM-TargetedMS2_pilot...   \n",
       "\n",
       "                                  no_extension_basename  \\\n",
       "0     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "1     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "2     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "3     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "4     20181019_JJ_KZ_Switchgrass_Greenhouse_Rhizo1_Q...   \n",
       "...                                                 ...   \n",
       "8629  20230831_EB_MdR_101544-059_FRCgw2_20230830_EXP...   \n",
       "8630  20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...   \n",
       "8631  20240112_JGI_MdR_109570-002_OMTSoil50g_Pilot_Q...   \n",
       "8632  20230919_EB_SMK_107002-011_CenturyExpPilot_202...   \n",
       "8633  20231005_JGI_TH_Internal_DOM-TargetedMS2_pilot...   \n",
       "\n",
       "                                          redu_filename  \\\n",
       "0     f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...   \n",
       "1     f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...   \n",
       "2     f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...   \n",
       "3     f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...   \n",
       "4     f.MSV000088543/ccms_peak/raw_data/20181019_JJ_...   \n",
       "...                                                 ...   \n",
       "8629                                                NaN   \n",
       "8630                                                NaN   \n",
       "8631                                                NaN   \n",
       "8632                                                NaN   \n",
       "8633                                                NaN   \n",
       "\n",
       "                                           title       dataset  ...  \\\n",
       "0     Exometabolomics of Switchgrass rhizosphere  MSV000088543  ...   \n",
       "1     Exometabolomics of Switchgrass rhizosphere  MSV000088543  ...   \n",
       "2     Exometabolomics of Switchgrass rhizosphere  MSV000088543  ...   \n",
       "3     Exometabolomics of Switchgrass rhizosphere  MSV000088543  ...   \n",
       "4     Exometabolomics of Switchgrass rhizosphere  MSV000088543  ...   \n",
       "...                                          ...           ...  ...   \n",
       "8629                                         NaN           NaN  ...   \n",
       "8630                                         NaN           NaN  ...   \n",
       "8631                                         NaN           NaN  ...   \n",
       "8632                                         NaN           NaN  ...   \n",
       "8633                                         NaN           NaN  ...   \n",
       "\n",
       "     DataSource in_redu_plant in_massive_dom_list  num_unique_spectra  \\\n",
       "0           NaN         False                True                  34   \n",
       "1           NaN         False                True                  32   \n",
       "2           NaN         False                True                  36   \n",
       "3           NaN         False                True                  43   \n",
       "4           NaN         False                True                  41   \n",
       "...         ...           ...                 ...                 ...   \n",
       "8629        NaN         False               False                 311   \n",
       "8630        NaN         False               False                 740   \n",
       "8631        NaN         False               False                 728   \n",
       "8632        NaN         False               False                 585   \n",
       "8633        NaN         False               False                 194   \n",
       "\n",
       "     num_unique_formula row_count  \\\n",
       "0                    30       456   \n",
       "1                    29       456   \n",
       "2                    34       456   \n",
       "3                    40       456   \n",
       "4                    38       456   \n",
       "...                 ...       ...   \n",
       "8629                258         2   \n",
       "8630                642         2   \n",
       "8631                640         2   \n",
       "8632                493         1   \n",
       "8633                159         1   \n",
       "\n",
       "                                             hash_value  \\\n",
       "0     4543026168108574362794479450808782822576102481...   \n",
       "1     1146699731202151078167183871657244067319867200...   \n",
       "2     6050222582699240527582470064019762021131872133...   \n",
       "3     3702313854198524301531740173462475658596229137...   \n",
       "4     3204540641109984802875185148711391962459030977...   \n",
       "...                                                 ...   \n",
       "8629  7691554974928442192395477242826347171018227719...   \n",
       "8630  2594972266128828903000352158747002890197414379...   \n",
       "8631  4209636828858950554459278668184188604433847647...   \n",
       "8632  1088936055166875952807734893139980155519399625...   \n",
       "8633  9739618844316565703298755352775119576894402083...   \n",
       "\n",
       "     fraction_within_half_tolerance total_formula  good_formula  \n",
       "0                               1.0            34            34  \n",
       "1                               1.0            32            32  \n",
       "2                               1.0            36            36  \n",
       "3                               1.0            43            43  \n",
       "4                               1.0            41            41  \n",
       "...                             ...           ...           ...  \n",
       "8629                            1.0           311           311  \n",
       "8630                            1.0           740           740  \n",
       "8631                            1.0           728           728  \n",
       "8632                            1.0           585           585  \n",
       "8633                            1.0           194           194  \n",
       "\n",
       "[2258 rows x 41 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def process_row(row):\n",
    "    row = row[-1]\n",
    "    temp = pd.read_parquet(row['buddy'])\n",
    "    if temp.shape[0]>0:\n",
    "        hash_value = hash_dataframe_row(row['buddy'])\n",
    "        temp['buddy'] = row['buddy']\n",
    "        return temp\n",
    "\n",
    "with Pool(20) as pool:\n",
    "    all_df = pool.map(process_row, df.iterrows())\n",
    "\n",
    "all_df = [o for o in all_df if o is not None]\n",
    "all_df = pd.concat(all_df)\n",
    "all_df.reset_index(inplace=True,drop=True)\n",
    "print(all_df.shape)\n",
    "all_df = pd.merge(df, all_df, on='buddy',how='inner')\n",
    "print(all_df.shape)\n",
    "# df = pd.concat([df, out], axis=1)\n",
    "all_df.reset_index(inplace=True,drop=True)\n",
    "all_df.index.name = 'original_index'\n",
    "all_df.reset_index(inplace=True,drop=False)\n",
    "\n",
    "all_df.to_pickle('/global/cfs/cdirs/metatlas/projects/carbon_network/all_spectra_backup.pkl')\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1074968, 55)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mz_tol = 0.002\n",
    "deltas = pd.read_csv('/global/cfs/cdirs/metatlas/projects/carbon_network/mdm_neutral_losses.csv')\n",
    "ref,ref2 = wt.get_p2d2(deltas,mz_tol=mz_tol)\n",
    "print(ref.shape)\n",
    "# ref = ref[ref['formula'].isin(formula_df['formula'])]\n",
    "ref.reset_index(inplace=True,drop=True)\n",
    "# ref2 = ref2[ref2['formula'].isin(formula_df['formula'])]\n",
    "ref2.reset_index(inplace=True,drop=True)\n",
    "print(ref.shape)\n",
    "ref_spec = ref['spectrum'].tolist()\n",
    "ref_pmz = ref['precursor_mz'].tolist()\n",
    "\n",
    "ref_spec_nl = ref2['nl_spectrum'].tolist()\n",
    "ref_pmz_nl = ref2['precursor_mz'].tolist()\n",
    "\n",
    "def score_df(df):\n",
    "    min_matches=3,\n",
    "    min_score=0.7,\n",
    "    override_matches=20\n",
    "\n",
    "    \n",
    "    q_cols = ['predicted_formula','precursor_mz']\n",
    "    r_cols = ['original_p2d2_index', 'formula','precursor_mz', 'inchi_key','name']\n",
    "    # q = q[q['predicted_formula'].isin(ref['formula'])].copy()\n",
    "    # q = query.head(10000)\n",
    "    if df.shape[0]==0:\n",
    "        return None\n",
    "    if 'mdm_mz_vals' not in df.columns:\n",
    "        return None\n",
    "    df['num_mdm_frags'] = df['mdm_mz_vals'].apply(lambda x: len(x) if type(x)!=float else 0)\n",
    "\n",
    "    df = df[df['num_mdm_frags']>0]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    df.index.name = 'original_index'\n",
    "    df.reset_index(inplace=True,drop=False)\n",
    "\n",
    "    df['nl_spectrum'] = df.apply(lambda x: np.asarray([x['mdm_mz_vals'],x['mdm_i_vals']]),axis=1)\n",
    "    df['original_spectrum'] = df.apply(lambda x: np.asarray([x['original_mz_vals'],x['original_i_vals']]),axis=1)\n",
    "\n",
    "    query_spec = df['original_spectrum'].tolist()\n",
    "    query_pmz = df['precursor_mz'].tolist()\n",
    "    query_spec_nl = df['nl_spectrum'].tolist()\n",
    "    query_pmz_nl = df['precursor_mz'].tolist()\n",
    "\n",
    "    d_specs = blink.discretize_spectra(query_spec,  ref_spec, query_pmz, ref_pmz, intensity_power=0.5, bin_width=0.001, tolerance=0.01,network_score=False)#,mass_diffs=mass_diffs)\n",
    "    d_specs_nl = blink.discretize_spectra(query_spec_nl,  ref_spec_nl, query_pmz_nl, ref_pmz_nl, intensity_power=0.5, bin_width=0.001, tolerance=0.01,network_score=False)#,mass_diffs=mass_diffs)\n",
    "    \n",
    "    def score_and_filter(specs,r,q,mz_tol=0.002,min_score=0.7,min_matches=3,override_matches=20,\n",
    "                         q_cols=['predicted_formula','precursor_mz'],\n",
    "                         r_cols=['original_p2d2_index', 'formula','precursor_mz', 'inchi_key','name']):\n",
    "        scores = blink.score_sparse_spectra(specs)\n",
    "        filtered_scores = blink.filter_hits(scores,min_score=min_score,min_matches=min_matches,override_matches=override_matches,)\n",
    "        mz_df = blink.reformat_score_matrix(filtered_scores)\n",
    "        mz_df = blink.make_output_df(mz_df)\n",
    "        for c in mz_df.columns:\n",
    "            mz_df[c] = mz_df[c].sparse.to_dense()\n",
    "\n",
    "        mz_df = pd.merge(mz_df,q[q_cols],left_on='query',right_index=True)\n",
    "        mz_df = pd.merge(mz_df,r[r_cols].add_suffix('_ref'),left_on='ref',right_index=True)\n",
    "        # mz_df = mz_df[mz_df['predicted_formula']==mz_df['formula']]\n",
    "        mz_df = mz_df[abs(mz_df['precursor_mz']-mz_df['precursor_mz_ref'])<mz_tol]\n",
    "        # mz_df.sort_values('score',ascending=False,inplace=True)\n",
    "        # mz_df.drop_duplicates('inchi_key_ref',keep='first',inplace=True)\n",
    "        return mz_df\n",
    "    orig_hits = score_and_filter(d_specs,ref,df,mz_tol=mz_tol,min_score=0.7,min_matches=3,override_matches=20,\n",
    "                             q_cols=['predicted_formula','precursor_mz'],\n",
    "                             r_cols=['original_p2d2_index', 'formula','precursor_mz', 'inchi_key','name'])\n",
    "    nl_hits = score_and_filter(d_specs_nl,ref2,df,mz_tol=mz_tol,min_score=0.7,min_matches=3,override_matches=20,\n",
    "                             q_cols=['predicted_formula','precursor_mz'],\n",
    "                             r_cols=['original_p2d2_index', 'formula','precursor_mz', 'inchi_key','name'])\n",
    "    temp = pd.merge(nl_hits,orig_hits,on=['query','original_p2d2_index_ref'],how='outer',suffixes=('_original','_nl'))\n",
    "    if temp.shape[0]==0:\n",
    "        return None\n",
    "    temp['max_score'] = temp[['score_original','score_nl']].max(axis=1)\n",
    "    temp['best_match_method'] = temp[['score_original','score_nl']].idxmax(axis=1)\n",
    "    temp.sort_values('max_score',ascending=False,inplace=True)\n",
    "    temp = temp[temp['max_score']>min_score]  #filter on score\n",
    "    temp['max_matches'] = 0\n",
    "    idx = temp['best_match_method']=='score_original'\n",
    "    temp.loc[idx,'max_matches'] = temp.loc[idx,'matches_original']\n",
    "    idx = temp['best_match_method']=='score_nl'\n",
    "    temp.loc[idx,'max_matches'] = temp.loc[idx,'matches_nl']\n",
    "    temp = temp[temp['max_matches']>=min_matches]  #filter on matches\n",
    "\n",
    "\n",
    "    cols = ['score_original','matches_original', 'score_nl', 'matches_nl']\n",
    "    temp.drop(columns=cols,inplace=True)\n",
    "    temp = pd.merge(temp,df[['original_index','precursor_mz','coisolated_precursor_count']].add_suffix('_query'),left_on='query',right_index=True)\n",
    "\n",
    "    idx_isolated = (temp['coisolated_precursor_count_query']>1) & (temp['best_match_method']=='score_original')\n",
    "    temp = temp[~idx_isolated] #filter on isolated precursor\n",
    "\n",
    "    cols = ['name', 'inchi_key', 'smiles','formula','precursor_mz','original_p2d2_index']\n",
    "    temp = pd.merge(temp,ref[cols],left_on='original_p2d2_index_ref',right_on='original_p2d2_index',how='left')\n",
    "\n",
    "    idx_precursor = (abs(temp['precursor_mz_query']-temp['precursor_mz'])<mz_tol)\n",
    "    temp = temp[idx_precursor] #filter on precursor m/z\n",
    "\n",
    "    temp.sort_values('max_score',ascending=False,inplace=True)\n",
    "\n",
    "    temp = temp.groupby('query').head(1)\n",
    "    temp.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    df = pd.merge(df,temp.add_suffix('_identity'),left_on='original_index',right_on='original_index_query_identity',how='left')\n",
    "    # df.drop(columns=['original_index_query_analog','original_p2d2_index','query'],inplace=True)\n",
    "\n",
    "    cols = ['original_index_query_identity',\n",
    "            'query_identity',\n",
    "            'precursor_mz_query_identity',\n",
    "            'coisolated_precursor_count_query_identity']\n",
    "    df.drop(columns=cols,inplace=True)\n",
    "    df.sort_values('max_score_identity',ascending=False,inplace=True)\n",
    "    df.drop_duplicates('inchi_key_identity',keep='first',inplace=True)\n",
    "    df = df[df['max_score_identity']>0]\n",
    "    if df.shape[0]==0:\n",
    "        return None\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_mass(formula):\n",
    "    # Regular expression to match elements and their counts\n",
    "    pattern = r'([A-Z][a-z]*)(\\d*)'    \n",
    "    mass = 0\n",
    "    pt = rdchem.GetPeriodicTable()\n",
    "\n",
    "    for el, count in re.findall(pattern, formula):\n",
    "        # If count is an empty string, it means there's only one atom of this element\n",
    "        count = int(count) if count else 1\n",
    "        mass += pt.GetMostCommonIsotopeMass(el) * count\n",
    "    return mass\n",
    "\n",
    "def process_row(row):\n",
    "    row = row[-1]\n",
    "    temp = pd.read_parquet(row['buddy'])\n",
    "    if temp.shape[0]>0:\n",
    "        temp['predicted_mass'] = temp['predicted_formula'].apply(lambda x: calculate_mass(x))\n",
    "        temp['predicted_mass'] = temp['predicted_mass'] - 1.007276\n",
    "        temp['mass_error'] = temp['precursor_mz'] - temp['predicted_mass']\n",
    "        count_good = temp[temp['mass_error'].abs() < 0.001].shape[0] #0.002 was the parameter used in the original code\n",
    "        fraction_good = count_good / temp.shape[0]\n",
    "        temp = score_df(temp)\n",
    "    else:\n",
    "        count_good = 0\n",
    "        fraction_good = 0\n",
    "    return temp#{'fraction_within_half_tolerance':fraction_good,'total_formula':temp.shape[0],'good_formula':count_good}\n",
    "\n",
    "with Pool(20) as pool:\n",
    "    out = pool.map(process_row, df.iterrows())\n",
    "# out = []\n",
    "# for (i,row) in df.iterrows():\n",
    "#     t = process_row(row)\n",
    "#     if t is not None:\n",
    "#         out.append(t)\n",
    "#     # break\n",
    "out = [o for o in out if o is not None]\n",
    "out = pd.concat(out)\n",
    "out.reset_index(inplace=True,drop=True)\n",
    "df = pd.merge(df, out, left_on='h5', right_on='filename', how='outer')\n",
    "# df = pd.concat([df, out], axis=1)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "# df.index.name = 'original_index'\n",
    "# df.reset_index(inplace=True,drop=False)\n",
    "# df\n",
    "# out = process_row([0,df.loc[9667]])\n",
    "# out = out[out['formula'].isin(formula_df['formula'])]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values('max_score_identity',ascending=False,inplace=True)\n",
    "# df.drop_duplicates('inchi_key_identity',keep='first',inplace=True)\n",
    "# # out['best_match_method_identity'].value_counts()\n",
    "# idx = out['formula_identity'].isin(formula_df['formula'])\n",
    "# out.loc[idx,'inchi_key_identity'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['num_mdm_frags'] = df['mdm_mz_vals'].apply(lambda x: len(x) if type(x)!=float else 0)\n",
    "\n",
    "# df = df[df['num_mdm_frags']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = pd.merge(df,formula_df,left_on='formula_identity',right_on='formula',how='left')\n",
    "df['isin_fticr_formula'] = df['formula_identity'].isin(formula_df['formula'])\n",
    "# print(len(df.loc[df['isin_fticr_formula'],'predicted_formula'].unique()),len(df['predicted_formula'].unique()),len(formula_df['formula'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # df = df[df['isin_fticr_formula']]\n",
    "# df['nl_spectrum'] = df.apply(lambda x: np.asarray([x['mdm_mz_vals'],x['mdm_i_vals']]),axis=1)\n",
    "# df['original_spectrum'] = df.apply(lambda x: np.asarray([x['original_mz_vals'],x['original_i_vals']]),axis=1)\n",
    "# # print(len(df.loc[df['isin_fticr_formula'],'predicted_formula'].unique()),len(df['predicted_formula'].unique()),len(formula_df['formula'].unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = score_df(df.sample(10000))\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mz_tol = 0.002\n",
    "# deltas = pd.read_csv('../data/mdm_neutral_losses.csv')\n",
    "# ref,ref2 = wt.get_p2d2(deltas,mz_tol=mz_tol)\n",
    "# ref = ref[ref['formula'].isin(df['predicted_formula'])]\n",
    "# ref2 = ref2[ref2['formula'].isin(df['predicted_formula'])]\n",
    "# ref = ref[ref['formula'].isin(formula_df['formula'])]\n",
    "# ref2 = ref2[ref2['formula'].isin(formula_df['formula'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = df['predicted_formula'].isin(ref['formula'])\n",
    "# query_spec = df.loc[idx,'original_spectrum'].tolist()\n",
    "# query_pmz = df.loc[idx,'precursor_mz'].tolist()\n",
    "# idx = df['predicted_formula'].isin(ref2['formula'])\n",
    "# query_spec_nl = df.loc[idx,'nl_spectrum'].tolist()\n",
    "# query_pmz_nl = df.loc[idx,'precursor_mz'].tolist()\n",
    "\n",
    "# ref_spec = ref['spectrum'].tolist()\n",
    "# ref_pmz = ref['precursor_mz'].tolist()\n",
    "\n",
    "# ref_spec_nl = ref2['nl_spectrum'].tolist()\n",
    "# ref_pmz_nl = ref2['precursor_mz'].tolist()\n",
    "\n",
    "# # polarity = 'negative'\n",
    "# # # import pickle as pickle\n",
    "# # from joblib import load\n",
    "\n",
    "# # with open('/global/homes/b/bpb/repos/blink/models/{}_random_forest.joblib'.format(polarity), 'rb') as out:\n",
    "# #     regressor = load(out)\n",
    "\n",
    "# # mass_diffs = [0, 14.0157, 12.000, 15.9949, 2.01565, 27.9949, 26.0157, 18.0106, 30.0106, 42.0106, 1.9792, 17.00284, 24.000, 13.97925, 1.00794, 40.0313]#, 43.993]\n",
    "\n",
    "# d_specs = blink.discretize_spectra(query_spec,  ref_spec, query_pmz, ref_pmz, intensity_power=0.5, bin_width=0.001, tolerance=0.01,network_score=False)#,mass_diffs=mass_diffs)\n",
    "# d_specs_nl = blink.discretize_spectra(query_spec_nl,  ref_spec_nl, query_pmz_nl, ref_pmz_nl, intensity_power=0.5, bin_width=0.001, tolerance=0.01,network_score=False)#,mass_diffs=mass_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.shape)\n",
    "# df = df[~df['predicted_formula'].str.contains('P|N|S')]\n",
    "# print(df.shape)\n",
    "# print(len(df.loc[df['isin_fticr_formula'],'predicted_formula'].unique()),len(df['predicted_formula'].unique()),len(formula_df['formula'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_assets(df,group_term='buddy'):\n",
    "    df = df[pd.notna(df['formula_identity'])]\n",
    "    result_true = df[df['isin_fticr_formula'] == True].groupby(group_term)['formula_identity'].nunique()\n",
    "    result_false = df[df['isin_fticr_formula'] == False].groupby(group_term)['formula_identity'].nunique()\n",
    "    combined_result = pd.concat([result_true, result_false], axis=1)\n",
    "    combined_result.columns = ['result_true', 'result_false']\n",
    "\n",
    "    combined_result.fillna(0, inplace=True)\n",
    "    combined_result['fraction_true'] = combined_result['result_true'] / (combined_result['result_true'] + combined_result['result_false'])\n",
    "    combined_result.reset_index(inplace=True,drop=False)\n",
    "    # Extract the 'fraction_true' values\n",
    "    fraction_true_values = combined_result['fraction_true'].values.reshape(-1, 1)\n",
    "\n",
    "    # Fit a Gaussian Mixture Model with 2 components\n",
    "    gmm = GaussianMixture(n_components=2, means_init=np.array([[0.3], [0.7]]))\n",
    "    gmm.fit(fraction_true_values)\n",
    "\n",
    "    # Get the means of the two Gaussian distributions\n",
    "    means = gmm.means_\n",
    "\n",
    "    # Print the means\n",
    "    print(\"Mean of the first Gaussian distribution:\", means[0][0])\n",
    "    print(\"Mean of the second Gaussian distribution:\", means[1][0])\n",
    "\n",
    "    cluster_labels = gmm.predict(fraction_true_values)\n",
    "\n",
    "    # Separate the two populations based on the cluster labels\n",
    "    population1 = fraction_true_values[cluster_labels == 0]\n",
    "    population2 = fraction_true_values[cluster_labels == 1]\n",
    "    min_val = fraction_true_values[cluster_labels == 1].min()\n",
    "    print(\"Minimum value of the higher distribution:\", fraction_true_values[cluster_labels == 1].min())\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the two populations\n",
    "    plt.hist(population1, bins=np.linspace(0,1,30), alpha=0.5, label='Population 1')\n",
    "    plt.hist(population2, bins=np.linspace(0,1,30), alpha=0.5, label='Population 2')\n",
    "    plt.xlabel('fraction_true')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    good_files = combined_result.loc[combined_result['fraction_true'] > min_val, 'buddy'].tolist()\n",
    "    \n",
    "    return good_files\n",
    "\n",
    "good_files = filter_assets(df)\n",
    "print(df.shape, len(good_files),len(df['buddy'].unique()))\n",
    "df = df[df['buddy'].isin(good_files)]\n",
    "print(df.shape, len(good_files),len(df['buddy'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_massive_ids = df.groupby('formula_identity')['massive_id'].nunique()\n",
    "# unique_massive_ids = unique_massive_ids[unique_massive_ids>1]\n",
    "# # fig,ax = plt.subplots()\n",
    "# # ax.hist(unique_massive_ids,bins=100)\n",
    "# # unique_massive_ids\n",
    "# # ax.set_yscale('log')\n",
    "# # ax.set_xscale('log')\n",
    "# # plt.show()\n",
    "# df = df[df['predicted_formula'].isin(unique_massive_ids.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_true = df[df['isin_fticr_formula'] == True].groupby('buddy')['predicted_formula'].nunique()\n",
    "# result_false = df[df['isin_fticr_formula'] == False].groupby('buddy')['predicted_formula'].nunique()\n",
    "# combined_result = pd.concat([result_true, result_false], axis=1)\n",
    "# combined_result.columns = ['result_true', 'result_false']\n",
    "\n",
    "# combined_result.fillna(0, inplace=True)\n",
    "# combined_result.reset_index(inplace=True,drop=False)\n",
    "\n",
    "# # combined_result = combined_result[combined_result['result_true'] + combined_result['result_false'] > 1000]\n",
    "# combined_result = combined_result[combined_result['buddy'].str.contains('MSV000088823')]\n",
    "# combined_result['buddy'] = combined_result['buddy'].apply(lambda x: os.path.basename(x).replace('.parquet','').replace('DOM_Interlab-LCMS_',''))\n",
    "# combined_result.sort_values('result_true',ascending=True,inplace=True)\n",
    "# combined_result['fraction_true'] = combined_result['result_true'] / (combined_result['result_true'] + combined_result['result_false'])\n",
    "# combined_result.reset_index(inplace=True)\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig,ax = plt.subplots(figsize=(18,8))\n",
    "# combined_result.plot(x='buddy', y=['result_true', 'result_false'], kind='bar',ax=ax,stacked=True)\n",
    "# # plt.xlabel('Massive ID')\n",
    "# ax.set_ylabel('Number of Unique Predicted Formulas')\n",
    "# # plt.title('Number of Unique Predicted Formulas by Massive ID')\n",
    "# plt.legend(['In FTICR', 'Not In FTICR'])\n",
    "# plt.tight_layout()\n",
    "# # combined_result.plot(x='massive_id', y=['result_true', 'result_false'], kind='bar', ax=ax, stacked=True)\n",
    "\n",
    "# # Add \"*\" above bars with 'fraction_true' less than 0.2\n",
    "# for i, row in combined_result.iterrows():\n",
    "#     if row['fraction_true'] < 0.20:\n",
    "#         ax.text(i, 1.00*(row['result_true'] + row['result_false']), \"*\", ha='center', va='bottom',fontsize=24)\n",
    "#         # ax.text(i,1,'*')\n",
    "\n",
    "# ax.set_ylabel('Number of Unique Predicted Formulas')\n",
    "# plt.legend(['In FTICR', 'Not In FTICR'])\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[pd.notna(df['formula_identity'])]\n",
    "k = 'inchi_key_identity'\n",
    "# k = 'formula_identity'\n",
    "result_true = temp[temp['isin_fticr_formula'] == True].groupby('massive_id')[k].nunique()\n",
    "result_false = temp[temp['isin_fticr_formula'] == False].groupby('massive_id')[k].nunique()\n",
    "combined_result = pd.concat([result_true, result_false], axis=1)\n",
    "combined_result.columns = ['result_true', 'result_false']\n",
    "combined_result.fillna(0, inplace=True)\n",
    "\n",
    "combined_result.sort_values('result_true',ascending=True,inplace=True)\n",
    "combined_result['fraction_true'] = combined_result['result_true'] / (combined_result['result_true'] + combined_result['result_false'])\n",
    "combined_result.reset_index(inplace=True)\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(18,8))\n",
    "combined_result.plot(x='massive_id', y=['result_true', 'result_false'], kind='bar',width=0.9,ax=ax,stacked=True)\n",
    "# plt.xlabel('Massive ID')\n",
    "\n",
    "\n",
    "\n",
    "# Add \"*\" above bars with 'fraction_true' less than 0.2\n",
    "for i, row in combined_result.iterrows():\n",
    "    if row['fraction_true'] < 0.20:\n",
    "        ax.text(i, 1.00*(row['result_true'] + row['result_false']), \"*\", ha='center', va='bottom',fontsize=24)\n",
    "        # ax.text(i,1,'*')\n",
    "\n",
    "ax.set_ylabel('Number of Unique MS2\\nIdentity Matches',fontsize=20)\n",
    "ax.set_xlabel('')\n",
    "ax.tick_params(axis='x', labelsize=18)\n",
    "ax.tick_params(axis='y', labelsize=18)\n",
    "\n",
    "plt.legend(['True', 'False'],title='In FT-ICR EOM',fontsize=18,title_fontsize=18)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('max_score_identity',ascending=False,inplace=True)\n",
    "df.drop_duplicates('inchi_key_identity',keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('/global/cfs/cdirs/metatlas/projects/carbon_network/top_scoring_inchikey.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('top_scoring_inchikey.pkl')\n",
    "all_df = pd.read_pickle('/global/cfs/cdirs/metatlas/projects/spectral_libraries/temp_backup.pkl')\n",
    "\n",
    "# df = pd.read_pickle('top_scoring_inchikey_lbl.pkl')\n",
    "# all_df = pd.read_pickle('/global/cfs/cdirs/metatlas/projects/spectral_libraries/temp_backup_lbl.pkl')\n",
    "\n",
    "all_df['nl_spectrum'] = all_df.apply(lambda x: np.asarray([x['mdm_mz_vals'],x['mdm_i_vals']]),axis=1)\n",
    "\n",
    "all_df['sum_frag_intensity'] = all_df['mdm_i_vals'].apply(lambda x: np.sum(x))\n",
    "all_df['original_spectrum'] = all_df['nl_spectrum']#df.apply(lambda x: np.asarray([x['original_mz_vals'],x['original_i_vals']]),axis=1)\n",
    "all_df = all_df[all_df['sum_frag_intensity']>0]\n",
    "all_df = all_df[pd.notna(all_df['predicted_formula'])]\n",
    "all_df = all_df[all_df['massive_id'].isin(df['massive_id'])]\n",
    "df['num_mdm_frags'] = df['mdm_mz_vals'].apply(lambda x: len(x))\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(all_df.shape)\n",
    "# all_df = all_df[~all_df['predicted_formula'].isin(df['predicted_formula'])]\n",
    "# print(all_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mz_tol = 0.002\n",
    "similarity_cutoff = 0.2\n",
    "isolation_tol = 0.5\n",
    "min_intensity_ratio = 2 #minimum intensity ratio between sum of fragments between two spectra\n",
    "my_polarity = 'negative' #either 'positive' or 'negative'\n",
    "\n",
    "deltas = pd.read_csv('../data/mdm_neutral_losses.csv')\n",
    "\n",
    "all_df['round3_precursor_mz'] = all_df['precursor_mz'].round(3)\n",
    "g = all_df.groupby('round3_precursor_mz')\n",
    "# g = all_df.groupby('predicted_formula')\n",
    "gg = [g.get_group(x) for x in g.groups]\n",
    "\n",
    "out = []\n",
    "for ggg in gg:\n",
    "    if ggg.shape[0]>1:\n",
    "        temp = wt.eliminate_duplicate_spectra(ggg,deltas,mz_tol=mz_tol,\n",
    "                                similarity_cutoff=similarity_cutoff,\n",
    "                                min_intensity_ratio=min_intensity_ratio)\n",
    "        out.append(temp)\n",
    "        # print(temp.shape[0],ggg.shape[0])\n",
    "    else:\n",
    "        out.append(ggg)\n",
    "        \n",
    "out = pd.concat(out)\n",
    "out.reset_index(inplace=True,drop=True)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = wt.eliminate_duplicate_spectra(out,deltas,mz_tol=mz_tol,\n",
    "                                similarity_cutoff=similarity_cutoff,\n",
    "                                min_intensity_ratio=min_intensity_ratio)\n",
    "out.reset_index(inplace=True,drop=True)\n",
    "out.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#18437 using formula nuclear option. 18813 without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True,drop=True)\n",
    "out.reset_index(inplace=True,drop=True)\n",
    "temp = pd.concat([df,out],axis=0)\n",
    "temp.reset_index(inplace=True,drop=True)\n",
    "mass_diffs = [0] + deltas['mass'].tolist()\n",
    "rem_df = wt.do_remblink_networking(temp,temp,mass_diffs=mass_diffs,\n",
    "                                   spectra_attr='nl_spectrum')\n",
    "# rem_df = wt.do_remblink_networking(out,df,spectra_attr='nl_spectrum')\n",
    "cols = ['ref','query','rem_predicted_score']\n",
    "rem_df = rem_df[cols]\n",
    "print(rem_df.shape)\n",
    "rem_df = rem_df[rem_df['rem_predicted_score']>0.1]\n",
    "print(rem_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'original_index' in temp.columns:\n",
    "    temp.drop(columns=['original_index'],inplace=True)\n",
    "temp.index.name = 'original_index'\n",
    "temp.reset_index(inplace=True,drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['original_index', \n",
    "       'massive_id', 'no_extension_basename','title', 'description', \n",
    "       'precursor_mz', 'isolated_precursor_mz', 'rt',\n",
    "       'coisolated_precursor_count', 'predicted_formula',\n",
    "       'estimated_fdr', 'predicted_mass', 'mass_error', 'num_mdm_frags',\n",
    "       'max_score_identity', 'best_match_method_identity',\n",
    "       'max_matches_identity', 'name_identity', 'inchi_key_identity',\n",
    "       'smiles_identity', 'formula_identity', 'precursor_mz_identity',\n",
    "       'original_p2d2_index_identity', 'isin_fticr_formula']\n",
    "\n",
    "# 'instrument', 'keywords', 'ChromatographyAndPhase',\n",
    "#        'YearOfAnalysis', 'SampleType', 'IonizationSourceAndPolarity',\n",
    "#        'SampleCollectionMethod', 'MassSpectrometer',\n",
    "#        'NCBITaxonomy', 'SampleExtractionMethod', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# # Create the graph from the similarity matrix\n",
    "G = nx.from_pandas_edgelist(rem_df,source='ref',target='query',edge_attr='rem_predicted_score')\n",
    "# (similarity_matrix > similarity_cutoff)\n",
    "# # Add node data from ms2_df to G\n",
    "# cols = list(set([c for c in temp.columns if not 'spect' in c]) - set(['obs','coisolated_precursor_mz_list','mol','filename', 'basename', 'experiment']))\n",
    "# cols = [c for c in cols if not 'mdm_' in c]\n",
    "# cols = [c for c in cols if not 'original_' in c]\n",
    "# cols = [c for c in cols if not 'nl_' in c]\n",
    "\n",
    "# cols = cols + ['stable']\n",
    "node_data = temp[cols].fillna('').to_dict(orient='index')\n",
    "\n",
    "nx.set_node_attributes(G, node_data)\n",
    "\n",
    "# print(len(G.nodes))\n",
    "# print(len(G.edges))\n",
    "\n",
    "# # Remove self-loops\n",
    "G.remove_edges_from([(u, v) for u, v in G.edges() if u == v])         \n",
    "\n",
    "# Remove isolates\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "print('nodes',len(G.nodes))\n",
    "print('edges',len(G.edges))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nx.write_graphml(G,'eom-net_0p1_new-rem-blink.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_weights = {}\n",
    "\n",
    "for node in G.nodes:\n",
    "    weights = [data['rem_predicted_score'] for _, _, data in G.edges(node, data=True)]\n",
    "    if weights:\n",
    "        max_weights[node] = max(weights)\n",
    "    else:\n",
    "        max_weights[node] = None  # or some other value indicating no connections\n",
    "\n",
    "weights = [v for k,v in max_weights.items() if v is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.hist(weights,bins=100)\n",
    "# ax.set_xlim(0)\n",
    "# ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from blink.utils import filter_top_k, filter_component_additive\n",
    "# filter_top_k(G,5,'rem_predicted_score')\n",
    "# print('nodes',len(G.nodes))\n",
    "# print('edges',len(G.edges))\n",
    "# nx.write_graphml(G,'eom-net_0p1_new-rem-blink_k5.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_jaccard_bonds(row):\n",
    "    smiles0 = row[0]\n",
    "    smiles1 = row[1]\n",
    "\n",
    "    # if (isinstance(smiles0, str)) & (isinstance(smiles1, str)):\n",
    "    mol0 = MolFromSmiles(smiles0)\n",
    "    mol1 = MolFromSmiles(smiles1)\n",
    "\n",
    "    res = rdFMCS.FindMCS([mol0, mol1], timeout=10, ringMatchesRingOnly=True)\n",
    "    # else:\n",
    "        # return 0\n",
    "\n",
    "    A = mol0.GetNumBonds()\n",
    "    B = mol1.GetNumBonds()\n",
    "    # try to grab res.numBonds\n",
    "    if min([A,B])>0:\n",
    "        TP = res.numBonds\n",
    "        jaccard = TP / ((A+B) - TP)\n",
    "    else:\n",
    "        jaccard = 0\n",
    "    \n",
    "    return jaccard\n",
    "\n",
    "def nodes_within_distance(source_node, graph, max_distance):\n",
    "    shortest_path_lengths = nx.single_source_shortest_path_length(graph, source_node)\n",
    "    nodes_within_distance = [node for node, distance in shortest_path_lengths.items() if distance <= max_distance]\n",
    "    return nodes_within_distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df = pd.read_pickle('top_scoring_inchikey.pkl')\n",
    "# df.columns\n",
    "# node_data = G.nodes(data=True)\n",
    "# node_data = pd.DataFrame(node_data)\n",
    "# node_data.columns = ['node','data']\n",
    "# node_data['data'] = node_data['data'].apply(lambda x: dict(x))\n",
    "# node_data = pd.concat([node_data.drop(['data'], axis=1), node_data['data'].apply(pd.Series)], axis=1)\n",
    "# node_data.reset_index(inplace=True,drop=True)\n",
    "# node_data = node_data[node_data['inchi_key_identity'].notna()]\n",
    "\n",
    "# # pink_nodes = [2064.0,\n",
    "# # 315.0,\n",
    "# # 1420.0,\n",
    "# # 598.0,\n",
    "# # 495.0,\n",
    "# # 536.0,\n",
    "# # 625.0,\n",
    "# # 623.0,\n",
    "# # 507.0,\n",
    "# # 266.0,\n",
    "# # 445.0,\n",
    "# # 1877.0,\n",
    "# # 5612.0,\n",
    "# # 755.0,\n",
    "# # 2886.0]\n",
    "\n",
    "# # green_nodes = [809.0,\n",
    "# # 9314.0,\n",
    "# # 7032.0,\n",
    "# # 7743.0,\n",
    "# # 213.0,\n",
    "# # 624.0,\n",
    "# # 597.0,\n",
    "# # 870.0,\n",
    "# # 269.0,\n",
    "# # 675.0,\n",
    "# # 854.0,\n",
    "# # 582.0,\n",
    "# # 1054.0,\n",
    "# # 430.0]\n",
    "\n",
    "# # pink_nodes = [str(x) for x in pink_nodes]\n",
    "# # green_nodes = [str(x) for x in green_nodes]\n",
    "\n",
    "# # pink_nodes = node_data[node_data['node'].isin(pink_nodes)]\n",
    "# # green_nodes = node_data[node_data['node'].isin(green_nodes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # node_data = node_data[node_data['node'].isin(pink_nodes + green_nodes)]\n",
    "# # node_data.shape\n",
    "# spectra_data = df[['nl_spectrum','original_spectrum','smiles_identity','inchi_key_identity','precursor_mz','massive_id','buddy']]\n",
    "# pink_nodes = spectra_data[spectra_data['inchi_key_identity'].isin(pink_nodes['inchi_key_identity'])]\n",
    "# green_nodes = spectra_data[spectra_data['inchi_key_identity'].isin(green_nodes['inchi_key_identity'])]\n",
    "# pink_nodes.reset_index(inplace=True,drop=True)\n",
    "# green_nodes.reset_index(inplace=True,drop=True)\n",
    "# spectra_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def do_remblink_networking(query,ref,spectra_attr='msv'):\n",
    "#     polarity = 'negative'\n",
    "#     # import pickle as pickle\n",
    "#     from joblib import load\n",
    "\n",
    "#     with open('{}_random_forest.joblib'.format(polarity), 'rb') as out:\n",
    "#         regressor = load(out)\n",
    "\n",
    "#     mass_diffs = [0, 14.0157, 12.000, 15.9949, 2.01565, 27.9949, 26.0157, 18.0106, 30.0106, 42.0106, 1.9792, 17.00284, 24.000, 13.97925, 1.00794, 40.0313]#, 43.993]\n",
    "\n",
    "#     query_spectra = query[spectra_attr].tolist()\n",
    "#     query_precursor_mzs = query.precursor_mz.tolist()\n",
    "\n",
    "#     ref_spectra = ref[spectra_attr].tolist()\n",
    "#     ref_precursor_mzs = ref.precursor_mz.tolist()\n",
    "\n",
    "#     d_specs = blink.discretize_spectra(query_spectra,  ref_spectra, query_precursor_mzs, ref_precursor_mzs, intensity_power=0.5, bin_width=0.001, tolerance=0.01,network_score=True,mass_diffs=mass_diffs)\n",
    "#     scores = blink.score_sparse_spectra(d_specs)\n",
    "#     stacked_scores, stacked_counts = blink.stack_network_matrices(scores)\n",
    "#     rem_scores, predicted_rows = blink.rem_predict(stacked_scores, scores, regressor,min_predicted_score=0.0001)\n",
    "#     score_rem_df, matches_rem_df = blink.make_rem_df(rem_scores, stacked_counts, predicted_rows, mass_diffs=mass_diffs)\n",
    "#     rem_df = pd.concat([score_rem_df,matches_rem_df],axis=1)\n",
    "\n",
    "#     rem_df = rem_df.sparse.to_dense()\n",
    "\n",
    "#     # match_cols = [m for m in rem_df.columns if 'matches' in m]\n",
    "#     # rem_df['matches'] = rem_df[match_cols].max(axis=1)\n",
    "\n",
    "#     # cols = ['formula', 'C', 'H', 'O', 'mw']\n",
    "#     # rem_df = pd.merge(rem_df,query[cols].add_suffix('_query'),left_on='query',right_index=True,how='inner')\n",
    "#     # rem_df = pd.merge(rem_df,ref[cols].add_suffix('_ref'),left_on='ref',right_index=True,how='inner')\n",
    "#     # # rem_df.sort_values('matches',inplace=True,ascending=False)\n",
    "#     # # rem_df = rem_df[rem_df['formula_ref']!=rem_df['formula_query']]\n",
    "\n",
    "#     # rem_df.sort_values('rem_predicted_score',inplace=True,ascending=False)\n",
    "#     # # rem_df.drop_duplicates(['formula_ref','formula_query'],inplace=True)\n",
    "\n",
    "#     # for e in ['mw','C','H','O']:\n",
    "#     #     rem_df['%s_diff'%e] = rem_df['%s_ref'%e] - rem_df['%s_query'%e]\n",
    "#     return rem_df\n",
    "\n",
    "# spectra_data.reset_index(inplace=True,drop=True)\n",
    "# rem_df = do_remblink_networking(spectra_data,spectra_data,spectra_attr='nl_spectrum')\n",
    "# # rem_df = wt.do_remblink_networking(out,df,spectra_attr='nl_spectrum')\n",
    "# cols = ['ref','query','rem_predicted_score']\n",
    "# rem_df = rem_df[cols]\n",
    "# rem_df.sort_values('rem_predicted_score',ascending=False,inplace=True)\n",
    "# # rem_df = rem_df[rem_df['rem_predicted_score']>0.1]\n",
    "# fig,ax = plt.subplots()\n",
    "# rem_df['rem_predicted_score'].apply(np.log10).hist(bins=200,ax=ax)\n",
    "# ax.set_xlabel('rem blink score')\n",
    "# # ax.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# temp = rem_df[rem_df['rem_predicted_score']<0.01]\n",
    "# temp = temp[temp['ref']!=temp['query']]\n",
    "# mcs = []\n",
    "# for i,row in temp.sample(500).iterrows():\n",
    "#     m = compute_jaccard_bonds((spectra_data.loc[row['ref'],'smiles_identity'],spectra_data.loc[row['query'],'smiles_identity']))\n",
    "#     mcs.append((m,row['rem_predicted_score']))\n",
    "# fig,ax = plt.subplots()\n",
    "# s = pd.DataFrame(mcs,columns=['mcs','score'])\n",
    "# s['mcs'].hist(ax=ax,bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# temp = rem_df[rem_df['rem_predicted_score']>0.01]\n",
    "# temp = temp[temp['ref']!=temp['query']]\n",
    "# mcs = []\n",
    "# for i,row in temp.iterrows():\n",
    "#     m = compute_jaccard_bonds((spectra_data.loc[row['ref'],'smiles_identity'],spectra_data.loc[row['query'],'smiles_identity']))\n",
    "#     mcs.append((m,row['rem_predicted_score']))\n",
    "# fig,ax = plt.subplots()\n",
    "# s = pd.DataFrame(mcs,columns=['mcs','score'])\n",
    "# s['mcs'].hist(ax=ax,bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # k = 'original_spectrum'\n",
    "# k = 'nl_spectrum'\n",
    "# g = green_nodes.loc[0,k]\n",
    "# p = pink_nodes.loc[0,k]\n",
    "# fig,ax = plt.subplots()\n",
    "# ax.vlines(g[0],0,g[1]**0.5,color='green')\n",
    "# ax.vlines(p[0]-18.0106,0,-1*(p[1]**0.5),color='pink')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# G = nx.read_graphml('eom-net_0p1_new-rem-blink_k3.graphml')\n",
    "# G = nx.read_graphml('eom-net_0p01_lbl.graphml')\n",
    "\n",
    "smiles_col = 'smiles_identity'\n",
    "\n",
    "# Maximum allowed distance between identity hits for clustering\n",
    "max_node_distance = 2\n",
    "\n",
    "# Minimum allows MCS for clustering\n",
    "min_mcs_difference = 0.4\n",
    "\n",
    "from rdkit.Chem import rdFMCS\n",
    "from rdkit.Chem import MolFromSmiles, MolFromSmarts, MolToInchiKey\n",
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import os\n",
    "# Get identity hits smiles for all nodes\n",
    "identity_smiles = nx.get_node_attributes(G, smiles_col)\n",
    "node_id = [k for k, v in identity_smiles.items() if isinstance(v,str)]\n",
    "identity_smiles = [v for k, v in identity_smiles.items() if isinstance(v,str)]\n",
    "df = pd.DataFrame(data=identity_smiles,columns=['smiles'])\n",
    "df['node_id'] = node_id\n",
    "df['mol'] = df['smiles'].apply(lambda x: MolFromSmiles(x) if x is not '' else None)\n",
    "df['inchi_key'] = df['mol'].apply(lambda x: MolToInchiKey(x) if x is not None else None)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = df[df['smiles'].str.contains('C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_most_common(classes):\n",
    "    class_counts = Counter(classes)\n",
    "    # Get the most common string\n",
    "    most_common_class = class_counts.most_common(1)[0][0]\n",
    "    return most_common_class\n",
    "\n",
    "classyfire_dir = '/global/cfs/cdirs/metatlas/projects/classyfire_annotations/'\n",
    "superclass_name = []\n",
    "class_name = []\n",
    "subclass_name = []\n",
    "iks = df.loc[pd.notna(df['inchi_key']),'inchi_key'].unique()\n",
    "for ik in iks:\n",
    "    f = '%s.json'%ik\n",
    "    f = os.path.join(classyfire_dir,f)\n",
    "    with open(f,'r') as fid:\n",
    "        cf = fid.read()\n",
    "    cf = json.loads(cf.strip())\n",
    "    if isinstance(cf,str):\n",
    "        cf = json.loads(cf)\n",
    "    # cf_json = json.dumps(cf)\n",
    "    if not 'subclass' in cf:\n",
    "        cf['subclass'] = {'name':None}\n",
    "    if not 'superclass' in cf:\n",
    "        cf['superclass'] = {'name':None}\n",
    "        cf['class'] = {'name':None}\n",
    "    if cf['subclass'] is None:\n",
    "        cf['subclass'] = {'name':None}\n",
    "    superclass_name.append(cf['superclass']['name'])\n",
    "    class_name.append(cf['class']['name'])\n",
    "    subclass_name.append(cf['subclass']['name'])\n",
    "\n",
    "temp = pd.DataFrame(index=iks)\n",
    "temp['superclass'] = superclass_name\n",
    "temp['class'] = class_name\n",
    "temp['subclass'] = subclass_name\n",
    "\n",
    "df = pd.merge(df,temp,left_on='inchi_key',right_index=True,how='left')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df['node_id']==246.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def min_additional_subgraph(graph, original_nodes,radius=1,min_count=0):\n",
    "    nodes = []\n",
    "    for node in original_nodes:\n",
    "        # Create an ego graph centered at the current node\n",
    "        \n",
    "        ego_subgraph = nx.ego_graph(graph, node,radius=radius)\n",
    "        nodes.extend(list(ego_subgraph.nodes))\n",
    "    df = pd.DataFrame(data=nodes,columns=['nodes'])\n",
    "    df = df.groupby('nodes').filter(lambda x: len(x) >= min_count)\n",
    "    nodes = df['nodes'].tolist() + original_nodes\n",
    "    \n",
    "    nodes = list(set(nodes))\n",
    "    nodes = sorted(nodes)\n",
    "    return nodes\n",
    "\n",
    "sc_df = pd.DataFrame()\n",
    "sc_df['node_id'] = df['node_id'].values\n",
    "sc_df['subclass'] = df['subclass'].values\n",
    "for class_name in sc_df.loc[pd.notna(sc_df['subclass']),'subclass'].unique():\n",
    "    idx = sc_df['subclass']==class_name\n",
    "    original_nodes = sc_df.loc[idx,'node_id'].tolist()\n",
    "    new_nodes = min_additional_subgraph(G, original_nodes,radius=2,min_count=3)\n",
    "    sc_df[class_name] = False\n",
    "    # idx = sc_df['node_id'].isin(original_nodes)\n",
    "    # sc_df.loc[idx,class_name] = True\n",
    "    idx = sc_df['node_id'].isin(new_nodes)\n",
    "    sc_df.loc[idx,class_name] = True\n",
    "sc_df.set_index('node_id',inplace=True)\n",
    "sc_df.drop(columns=['subclass'],inplace=True)\n",
    "# For each row in the DataFrame\n",
    "# If the sum of the row is greater than 1\n",
    "# Find the class with the highest frequency\n",
    "# Set all other classes to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a list of the classes that are most common\n",
    "ranked_frequency = sc_df.sum(axis=0).sort_values(ascending=False)\n",
    "for i,row in sc_df[sc_df.sum(axis=1)>1].iterrows():\n",
    "    keep_class = ranked_frequency[row[row==True].index].sort_values(ascending=False).index[0]\n",
    "    idx = row[row==True].index\n",
    "    idx = idx[idx!=keep_class]\n",
    "    sc_df.loc[i,idx] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc_df[sc_df['Amino acids, peptides, and analogues']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc_df.loc[11474.0].sort_values()\n",
    "# sc_df.loc[246.0,'Amino acids, peptides, and analogues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for any class that has an ID in the original, reset it back to its original state\n",
    "for i,row in df.iterrows():\n",
    "    sc_df.loc[row['node_id'],row['subclass']] = True\n",
    "\n",
    "\n",
    "# recomute the ranked frequency now that ambiguous classes have been resolved\n",
    "ranked_frequency = sc_df.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# #######################\n",
    "# # Build Distance Matrix\n",
    "# #######################\n",
    "\n",
    "# # Calculate all pairs shortest path lengths\n",
    "# all_pairs_lengths = dict(nx.all_pairs_shortest_path_length(G))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # Get a list of all nodes in the graph\n",
    "# nodes = list(G.nodes())\n",
    "\n",
    "# # Create a matrix to store the distances between nodes\n",
    "# num_nodes = len(nodes)\n",
    "# distance_matrix = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "# # Fill in the distance matrix with the calculated distances\n",
    "# for i in range(num_nodes):\n",
    "#     for j in range(num_nodes):\n",
    "        \n",
    "#         if nodes[j] not in all_pairs_lengths[nodes[i]].keys():\n",
    "#             distance_matrix[i, j] = None\n",
    "#         else:\n",
    "#             distance_matrix[i, j] = all_pairs_lengths[nodes[i]][nodes[j]]\n",
    "            \n",
    "# # Replace diagonal values (self-connections) with None\n",
    "# np.fill_diagonal(distance_matrix, None)\n",
    "\n",
    "# print(distance_matrix.shape)\n",
    "# # distance_matrix[np.isnan(distance_matrix)] = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pair_index = []\n",
    "# for n in df['node_id']:\n",
    "#     idx = nodes.index(n)\n",
    "#     pair_index.append(idx)\n",
    "# df['pair_index'] = pair_index\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rows, cols = neighbor_distance_matrix.nonzero()\n",
    "# neighbor_pairs = np.array([rows, cols]).T\n",
    "# neighbor_pairs = pd.DataFrame(neighbor_pairs, columns=['node1', 'node2'])\n",
    "# neighbor_pairs['distance'] = distance_matrix[neighbor_pairs['node1'], neighbor_pairs['node2']]\n",
    "# cols = ['pair_index','node_id','subclass','superclass','class']\n",
    "# neighbor_pairs = pd.merge(neighbor_pairs,df[cols].add_suffix('_1'),left_on='node1',right_on='pair_index_1')\n",
    "# neighbor_pairs = pd.merge(neighbor_pairs,df[cols].add_suffix('_2'),left_on='node2',right_on='pair_index_2')\n",
    "# neighbor_pairs.drop(columns=['pair_index_1','pair_index_2'],inplace=True)\n",
    "# idx = neighbor_pairs['class_1'] == neighbor_pairs['class_2']\n",
    "# neighbor_pairs = neighbor_pairs[idx]\n",
    "# neighbor_pairs.reset_index(inplace=True,drop=True)\n",
    "# neighbor_pairs.rename({'subclass_1':'subclass','superclass_1':'superclass','class_1':'class'},axis=1,inplace=True)\n",
    "# neighbor_pairs.drop(columns=['superclass_2','class_2','subclass_2'],inplace=True)\n",
    "\n",
    "\n",
    "# neighbor_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neighbor_distance_matrix = distance_matrix <= max_node_distance\n",
    "# rows, cols = neighbor_distance_matrix.nonzero()\n",
    "# neighbor_pairs = np.array([rows, cols]).T\n",
    "# neighbor_pairs = pd.DataFrame(neighbor_pairs, columns=['node1', 'node2'])\n",
    "# neighbor_pairs['distance'] = distance_matrix[neighbor_pairs['node1'], neighbor_pairs['node2']]\n",
    "# cols = ['pair_index','node_id','subclass','superclass','class']\n",
    "# neighbor_pairs = pd.merge(neighbor_pairs,df[cols].add_suffix('_1'),left_on='node1',right_on='pair_index_1')\n",
    "# neighbor_pairs = pd.merge(neighbor_pairs,df[cols].add_suffix('_2'),left_on='node2',right_on='pair_index_2')\n",
    "# neighbor_pairs.drop(columns=['pair_index_1','pair_index_2'],inplace=True)\n",
    "# idx = neighbor_pairs['class_1'] == neighbor_pairs['class_2']\n",
    "# neighbor_pairs = neighbor_pairs[idx]\n",
    "# neighbor_pairs.reset_index(inplace=True,drop=True)\n",
    "# neighbor_pairs.rename({'subclass_1':'subclass','superclass_1':'superclass','class_1':'class'},axis=1,inplace=True)\n",
    "# neighbor_pairs.drop(columns=['superclass_2','class_2','subclass_2'],inplace=True)\n",
    "\n",
    "\n",
    "# neighbor_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neighbor_pairs['subclass'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neighbor_pairs['subclass'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sc_df = pd.DataFrame(data=nodes,columns=['node_id'])\n",
    "# for class_name in neighbor_pairs['subclass'].unique():\n",
    "#     original_nodes = []\n",
    "#     temp = neighbor_pairs[neighbor_pairs['subclass']==class_name]\n",
    "#     for i,row in temp.iterrows():\n",
    "#         original_nodes.append(row['node_id_1'])\n",
    "#         original_nodes.append(row['node_id_2'])\n",
    "#     new_nodes = min_additional_subgraph(G, original_nodes)\n",
    "#     sc_df[class_name] = False\n",
    "#     idx = sc_df['node_id'].isin(new_nodes)\n",
    "#     sc_df.loc[idx,class_name] = True\n",
    "# sc_df.set_index('node_id',inplace=True)\n",
    "# # For each row in the DataFrame\n",
    "# # If the sum of the row is greater than 1\n",
    "# # Find the class with the highest frequency\n",
    "# # Set all other classes to False\n",
    "\n",
    "\n",
    "\n",
    "# # make a list of the classes that are most common\n",
    "# ranked_frequency = sc_df.sum(axis=0).sort_values(ascending=False)\n",
    "# for i,row in sc_df[sc_df.sum(axis=1)>1].iterrows():\n",
    "#     keep_class = ranked_frequency[row[row==True].index].sort_values(ascending=False).index[0]\n",
    "#     idx = row[row==True].index\n",
    "#     idx = idx[idx!=keep_class]\n",
    "#     sc_df.loc[i,idx] = False\n",
    "\n",
    "# # for any class that has an ID reset it back to its original state\n",
    "# sc_df.iloc[neighbor_pairs['node1'].tolist()] = False\n",
    "# sc_df.iloc[neighbor_pairs['node2'].tolist()] = False\n",
    "# for i,row in neighbor_pairs.iterrows():\n",
    "#     sc_df.loc[row['node1'],row['subclass']] = True\n",
    "#     sc_df.loc[row['node2'],row['subclass']] = True\n",
    "\n",
    "\n",
    "# # recomute the ranked frequency now that ambiguous classes have been resolved\n",
    "# ranked_frequency = sc_df.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = sc_df.columns\n",
    "sc_df = sc_df.reset_index().melt(id_vars='node_id',value_vars=cols)\n",
    "idx = sc_df['value']==True\n",
    "sc_df = sc_df[idx]\n",
    "sc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc_df = sc_df[pd.notna(sc_df['variable'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc_df[sc_df['node_id']==2533.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc_df[sc_df['node_id']==246.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc_df.value_counts('variable').head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add cluster labels to graph\n",
    "cluster_dict = sc_df.copy()\n",
    "cluster_dict.rename(columns={'variable':'structural_cluster_subclassname'},inplace=True)\n",
    "print(cluster_dict.shape)\n",
    "cluster_dict = pd.merge(df[['class','superclass','subclass']].drop_duplicates('subclass'),cluster_dict,left_on='subclass',right_on='structural_cluster_subclassname',how='right')\n",
    "print(cluster_dict.shape)\n",
    "# need to understand why there are duplicates\n",
    "cluster_dict.drop_duplicates('node_id',inplace=True)\n",
    "cluster_dict.set_index('node_id',inplace=True)\n",
    "cluster_dict.drop(columns=['structural_cluster_subclassname','value'],inplace=True)\n",
    "cluster_dict.fillna('',inplace=True)\n",
    "cluster_dict = cluster_dict.to_dict(orient='index')\n",
    "\n",
    "nx.set_node_attributes(G, cluster_dict)\n",
    "# cluster_dict\n",
    "# nx.set_node_attributes(G, cluster_dict, 'mcs_structural_cluster_number')\n",
    "# len(clusters),len(set(clusters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx.write_graphml(G,'eom-net_0p1_subclass_clusters.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from blink.utils import filter_top_k, filter_component_additive\n",
    "# filter_top_k(G,4,'rem_predicted_score')\n",
    "G = nx.maximum_spanning_tree(G)\n",
    "print('nodes',len(G.nodes))\n",
    "print('edges',len(G.edges))\n",
    "nx.write_graphml(G,'eom-net_0p1_subclass_clusters_mst.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "G = nx.read_graphml('eom-net_0p1_subclass_clusters.graphml')\n",
    "df = G.nodes(data=True)\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = ['node','data']\n",
    "df['data'] = df['data'].apply(lambda x: dict(x))\n",
    "df = pd.concat([df.drop(['data'], axis=1), df['data'].apply(pd.Series)], axis=1)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df['consensus_class'] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of each subclass\n",
    "subclass_counts = df['subclass'].value_counts()\n",
    "\n",
    "# Get the subclasses that have at least 100 values\n",
    "large_subclasses = subclass_counts[subclass_counts >= 100].index\n",
    "\n",
    "# Set the consensus_class for large subclasses\n",
    "df.loc[df['subclass'].isin(large_subclasses), 'consensus_class'] = df.loc[df['subclass'].isin(large_subclasses), 'subclass']\n",
    "\n",
    "# Get the subclasses that have less than 100 values\n",
    "small_subclasses = subclass_counts[subclass_counts < 100].index\n",
    "\n",
    "# Set the consensus_class for small subclasses\n",
    "df.loc[df['subclass'].isin(small_subclasses), 'consensus_class'] = df.loc[df['subclass'].isin(small_subclasses), 'class']\n",
    "\n",
    "# Get the subclasses that have less than 100 values\n",
    "class_counts = df['consensus_class'].value_counts()\n",
    "small_classes = class_counts[class_counts < 100].index\n",
    "\n",
    "# Set the consensus_class for small subclasses\n",
    "df.loc[df['consensus_class'].isin(small_classes), 'consensus_class'] = df.loc[df['consensus_class'].isin(small_classes), 'superclass']\n",
    "\n",
    "df = df[['node','consensus_class']]\n",
    "\n",
    "df.loc[df['consensus_class'].map(df['consensus_class'].value_counts()) < 100, 'consensus_class'] = None\n",
    "\n",
    "df.fillna('',inplace=True)\n",
    "df.value_counts('consensus_class')\n",
    "nx.set_node_attributes(G, df.set_index('node')['consensus_class'].to_dict(), 'consensus_class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.maximum_spanning_tree(G)\n",
    "nx.write_graphml(G, 'graph_with_consensus_class.graphml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_weights = {}\n",
    "\n",
    "for node in G.nodes:\n",
    "    weights = [data['rem_predicted_score'] for _, _, data in G.edges(node, data=True)]\n",
    "    if weights:\n",
    "        max_weights[node] = max(weights)\n",
    "    else:\n",
    "        max_weights[node] = None  # or some other value indicating no connections\n",
    "\n",
    "weights = [v for k,v in max_weights.items() if v is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "# ax.hist(weights,bins=100)\n",
    "ax.hist(weights, bins=100, density=True, histtype=\"step\",\n",
    "                               cumulative=True, label=\"Cumulative histogram\")\n",
    "# ax.set_xlim(0)\n",
    "# ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# G = nx.read_graphml('eom-net_0p1_subclass_clusters_mst.graphml')\n",
    "\n",
    "# pos = nx.nx_agraph.graphviz_layout(G, prog='neato')\n",
    "\n",
    "# nx.draw(G, pos, with_labels=False, font_weight='bold', node_color='lightblue', node_size=30)\n",
    "# plt.title(\"Nodes associated with a structural cluster\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get identity hits smiles for all nodes\n",
    "identity_smiles = nx.get_node_attributes(G, smiles_col)\n",
    "nodes_with_hits = list(identity_smiles.keys())\n",
    "\n",
    "# Get all node pairs within distance\n",
    "neighbor_distance_matrix = distance_matrix <= max_node_distance\n",
    "rows, cols = neighbor_distance_matrix.nonzero()\n",
    "neighbor_pairs = np.array([rows, cols]).T\n",
    "\n",
    "# # Define a function to compute jaccard bonds\n",
    "# def compute_jaccard_bonds_parallel(args):\n",
    "#     pair, nodes, nodes_with_hits, identity_smiles = args\n",
    "#     node0 = nodes[pair[0]]\n",
    "#     node1 = nodes[pair[1]]\n",
    "    \n",
    "#     if node0 not in nodes_with_hits or node1 not in nodes_with_hits:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         smiles0 = identity_smiles[node0]\n",
    "#         smiles1 = identity_smiles[node1]\n",
    "        \n",
    "#         return compute_jaccard_bonds(smiles0, smiles1)\n",
    "# neighbor_pairs[:3,:],nodes[:3],identity_smiles['0.0']\n",
    "smiles_pairs = [(identity_smiles[nodes[pair[0]]],identity_smiles[nodes[pair[1]]],pair[0],pair[1]) for pair in neighbor_pairs]\n",
    "smiles_pairs = [(smiles1, smiles2,pair0,pair1) for smiles1, smiles2, pair0,pair1 in smiles_pairs if isinstance(smiles1, str) and isinstance(smiles2, str)]\n",
    "# compute_jaccard_bonds(smiles_pairs[0])\n",
    "# results = []\n",
    "# for i in smiles_pairs[:3000]:\n",
    "    # results.append(compute_jaccard_bonds(i))\n",
    "\n",
    "# with Pool(20) as pool:\n",
    "#     mcs_results = pool.map(compute_jaccard_bonds, smiles_pairs[:1000])\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    mcs_results = list(executor.map(compute_jaccard_bonds, smiles_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# nonzero_jaccard_len = len([jaccard_bonds for jaccard_bonds in neighbor_jaccard_bonds if jaccard_bonds is not None])\n",
    "# print(nonzero_jaccard_len)\n",
    "min_mcs_difference\n",
    "from scipy.cluster import hierarchy\n",
    "import matplotlib.pyplot as plt\n",
    "min_mcs_difference = 0.4\n",
    "\n",
    "row_indices = [pair[2] for pair in smiles_pairs]\n",
    "col_indices = [pair[3] for pair in smiles_pairs]\n",
    "\n",
    "x = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "x[row_indices,col_indices] = mcs_results\n",
    "y = x[np.triu_indices(x.shape[0],1)]\n",
    "y = 1 - y\n",
    "\n",
    "# fig,ax = plt.subplots()\n",
    "# dn1 = hierarchy.dendrogram(Z,ax=ax)\n",
    "Z = hierarchy.linkage(y, method='single')\n",
    "\n",
    "clusters = hierarchy.fcluster(Z, t=min_mcs_difference, criterion='distance')\n",
    "\n",
    "# Add cluster labels to graph\n",
    "cluster_dict = dict(zip(nodes, clusters))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_structural_cluster_number')\n",
    "# len(clusters),len(set(clusters))\n",
    "\n",
    "cluster_counts = np.bincount(clusters)\n",
    "print(len(clusters),len(set(clusters)),len(set(clusters[np.in1d(clusters,np.where(cluster_counts>1))])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "original_index = nx.get_node_attributes(G, 'original_index')\n",
    "mcs_structural_cluster_number = nx.get_node_attributes(G, 'mcs_structural_cluster_number')\n",
    "smiles = nx.get_node_attributes(G,smiles_col)\n",
    "node_id = {k:k for k in G.nodes()}\n",
    "\n",
    "df = pd.DataFrame({'node_id':node_id,'smiles':smiles,'original_index': original_index, 'mcs_structural_cluster_number': mcs_structural_cluster_number})\n",
    "df = df[pd.notna(df['smiles'])]\n",
    "df = df.groupby('mcs_structural_cluster_number').filter(lambda x: len(x) >= 2)\n",
    "df.sort_values('mcs_structural_cluster_number', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "dfs = [d for _,d in df.groupby('mcs_structural_cluster_number')]\n",
    "out = []\n",
    "for i,dd in enumerate(dfs):\n",
    "    nodes = dd['node_id'].tolist()\n",
    "    new_nodes = min_additional_subgraph(G, nodes)\n",
    "    mols = [MolFromSmiles(s) for s in dd['smiles'].tolist()]\n",
    "    res = rdFMCS.FindMCS(mols,timeout=120,ringMatchesRingOnly=True,threshold=0.8)\n",
    "    num_bonds = [m.GetNumBonds() for m in mols]\n",
    "    mcs = res.numBonds / np.min(num_bonds)\n",
    "    # len(n),dd.shape[0],n,sorted(dd['node_id'].tolist())\n",
    "    # dd['new_nodes'] = None\n",
    "    temp = pd.DataFrame()\n",
    "    temp['node_id'] = new_nodes \n",
    "    temp = pd.merge(temp,dd,on='node_id',how='outer')\n",
    "    temp['mcs'] = mcs\n",
    "    temp['mcs_structural_cluster_number'] = i\n",
    "    temp['structural_pattern'] = res.smartsString\n",
    "    temp['mols'] = [mols for _ in range(temp.shape[0])]\n",
    "    # temp['mcs_structural_cluster_number'] = i\n",
    "    temp.drop(columns=['original_index'])\n",
    "    out.append(temp)\n",
    "\n",
    "\n",
    "df = pd.concat(out)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "df_mol_cluster = df[['mcs_structural_cluster_number','structural_pattern','mols','mcs']].copy()\n",
    "\n",
    "df_mol_cluster.drop_duplicates('mcs_structural_cluster_number',inplace=True)\n",
    "df_mol_cluster.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df_mol_cluster['num_mols']= df_mol_cluster['mols'].apply(lambda x: len(x))\n",
    "\n",
    "df_mol_cluster.sort_values('num_mols',inplace=True)\n",
    "\n",
    "df_mol_cluster.reset_index(drop=True,inplace=True)\n",
    "# p = df_mol_cluster.loc[0,'structural_pattern']\n",
    "# mol = Chem.MolFromSmarts(p)\n",
    "# s = Chem.MolToSmiles(mol)\n",
    "# mol = Chem.MolFromSmiles(s)\n",
    "# mol\n",
    "df_mol_cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pats = [Chem.MolToSmiles(Chem.MolFromSmarts(p)) for p in df_mol_cluster['structural_pattern'].tolist()]\n",
    "mcs_results = []\n",
    "for i,p1 in enumerate(pats):\n",
    "    print(i)\n",
    "    for j,p2 in enumerate(pats):\n",
    "        if i > j:\n",
    "            if (p1 is not None) & (p2 is not None):\n",
    "                try:\n",
    "                    mcs = compute_jaccard_bonds((p1, p2))\n",
    "                except ValueError as e:\n",
    "                    if str(e) == \"molecule is None\":\n",
    "                        mcs = 0\n",
    "                    else:\n",
    "                        raise e\n",
    "            else:\n",
    "                mcs = 0\n",
    "            mcs_results.append({'pat_1':i,'pat_2':j,'mcs':mcs})\n",
    "            # print(p1,p2,Chem.MolFromSmiles(p1).HasSubstructMatch(Chem.MolFromSmiles(p2)))\n",
    "mcs_results = pd.DataFrame(mcs_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "x = mcs_results.pivot(index='pat_1',columns='pat_2',values='mcs')\n",
    "x = x.values\n",
    "# x = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "# x[row_indices,col_indices] = mcs_results\n",
    "y = x[np.tril_indices(x.shape[0],0)]\n",
    "y = 1 - y\n",
    "\n",
    "Z = hierarchy.linkage(y, method='ward')\n",
    "clusters = hierarchy.fcluster(Z, t=4, criterion='maxclust')\n",
    "\n",
    "\n",
    "# # Add cluster labels to graph\n",
    "# cluster_dict = dict(zip(nodes, clusters))\n",
    "# nx.set_node_attributes(G, cluster_dict, 'mcs_structural_cluster_number')\n",
    "# # len(clusters),len(set(clusters))\n",
    "\n",
    "# cluster_counts = np.bincount(clusters)\n",
    "# print(len(clusters),len(set(clusters)),len(set(clusters[np.in1d(clusters,np.where(cluster_counts>1))])))\n",
    "df_mol_cluster['mcs_higher_cluster'] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import json\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def get_most_common(classes):\n",
    "    class_counts = Counter(classes)\n",
    "    # Get the most common string\n",
    "    most_common_class = class_counts.most_common(1)[0][0]\n",
    "    return most_common_class\n",
    "\n",
    "classyfire_dir = '/global/cfs/cdirs/metatlas/projects/classyfire_annotations/'\n",
    "superclass_name = []\n",
    "class_name = []\n",
    "for i,row in df_mol_cluster.iterrows():\n",
    "    superclasses = []\n",
    "    classes = []\n",
    "    for m in row['mols']:\n",
    "        f = '%s.json'%Chem.MolToInchiKey(m)\n",
    "        f = os.path.join(classyfire_dir,f)\n",
    "        with open(f,'r') as fid:\n",
    "            cf = fid.read()\n",
    "        cf = json.loads(cf.strip())\n",
    "        if isinstance(cf,str):\n",
    "            cf = json.loads(cf)\n",
    "        # cf_json = json.dumps(cf)\n",
    "        if not 'superclass' in cf:\n",
    "            cf['superclass'] = {'name':None}\n",
    "            cf['class'] = {'name':None}\n",
    "        superclasses.append(cf['superclass']['name'])\n",
    "        classes.append(cf['class']['name'])\n",
    "    # Count the occurrences of each string in the classes list\n",
    "    classes = [c for c in classes if c is not None]\n",
    "    superclasses = [c for c in superclasses if c is not None]\n",
    "    if len(classes) == 0:\n",
    "        class_name.append(None)\n",
    "        superclass_name.append(None)\n",
    "    else:    \n",
    "        # Print the most common class\n",
    "        class_name.append(get_most_common(classes))\n",
    "        superclass_name.append(get_most_common(superclasses))\n",
    "df_mol_cluster['superclass'] = superclass_name\n",
    "df_mol_cluster['class'] = class_name\n",
    "df_mol_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mol_cluster.value_counts('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "outdir = '/global/homes/b/bpb/repos/scndb/data/struct_clusters_quartered'\n",
    "if os.path.exists(outdir):\n",
    "    shutil.rmtree(outdir)\n",
    "    # os.rmdir(outdir)\n",
    "os.makedirs(outdir)\n",
    "\n",
    "\n",
    "dfs = [d for _,d in df_mol_cluster.groupby('mcs_higher_cluster')]\n",
    "for dd in dfs:\n",
    "    mol_list = []\n",
    "    my_legend = []\n",
    "    for i,row in dd.iterrows():\n",
    "        mol_list.extend(row['mols'])\n",
    "        my_legend.extend(['%d'%row['mcs_structural_cluster_number'] for _ in range(len(row['mols']))])\n",
    "    \n",
    "    # Smarts pattern for common substructure\n",
    "    pat = MolFromSmarts(dd['structural_pattern'].tolist()[0])\n",
    "\n",
    "    image = MolsToGridImage(mol_list, molsPerRow=20, subImgSize=(300, 300), useSVG=True,maxMols=1000,legends=my_legend)\n",
    "                            #  highlightAtomLists=highlist_list,highlightAtomColors=[highlight_color]*len(mols))\n",
    "\n",
    "    # Display the image\n",
    "    outfile = os.path.join(outdir,'{}.svg'.format(dd['mcs_higher_cluster'].tolist()[0]))\n",
    "    with open(outfile,'w') as fid:\n",
    "        fid.write(image.data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# original_index = nx.get_node_attributes(G, 'original_index')\n",
    "# mcs_structural_cluster_number = nx.get_node_attributes(G, 'mcs_structural_cluster_number')\n",
    "# smiles = nx.get_node_attributes(G,smiles_col)\n",
    "\n",
    "# df = pd.DataFrame({'smiles':smiles,'original_index': original_index, 'mcs_structural_cluster_number': mcs_structural_cluster_number})\n",
    "# df = df[pd.notna(df['smiles'])]\n",
    "# df = df.groupby('mcs_structural_cluster_number').filter(lambda x: len(x) >= 2)\n",
    "# df.sort_values('mcs_structural_cluster_number', inplace=True)\n",
    "# df = df[df['mcs_structural_cluster_number']>0]\n",
    "# my_list = [MolFromSmiles(m) for m in df['smiles'].values]\n",
    "# my_legend = ['%d'%m for m in df['mcs_structural_cluster_number'].values]\n",
    "# image = MolsToGridImage(my_list, molsPerRow=10,maxMols=1000,legends=my_legend,useSVG=True)\n",
    "\n",
    "# outfile = os.path.join(outdir,'AllStructuralClusters_massive.svg')\n",
    "# with open(outfile,'w') as fid:\n",
    "#     fid.write(image.data)\n",
    "\n",
    "\n",
    "# shutil.make_archive('../data/structural_clusters_massive', 'zip', '.', outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n",
    "\n",
    "\n",
    "node_id = {k:k for k in G.nodes()}\n",
    "node_id = pd.Series(node_id)\n",
    "node_id = node_id.to_frame()\n",
    "node_id.columns = ['node_id']\n",
    "node_id = pd.merge(node_id,df,on='node_id',how='left')\n",
    "# node_id = node_id[['node_id','structural_pattern','mcs','mcs_structural_cluster_number']]\n",
    "node_id['structural_pattern'] = node_id['structural_pattern'].fillna('')\n",
    "node_id['mcs'] = node_id['mcs'].fillna(0)\n",
    "node_id['mcs_structural_cluster_number'] = node_id['mcs_structural_cluster_number'].fillna(-1)\n",
    "node_id['mcs_structural_cluster_number'] = node_id['mcs_structural_cluster_number'].astype(int)\n",
    "node_id['structural_pattern'] = node_id['structural_pattern'].astype(str)\n",
    "node_id['mcs'] = node_id['mcs'].astype(float)\n",
    "node_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add cluster labels to graph\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['structural_pattern'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_structural_pattern')\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['mcs'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_similarity')\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['mcs_structural_cluster_number'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_structural_cluster_number')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(G, 'eom-net-0p01-all-clust.graphml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "outdir = '/global/homes/b/bpb/repos/scndb/data/struct_clusters_al-v2'\n",
    "if os.path.exists(outdir):\n",
    "    shutil.rmtree(outdir)\n",
    "    # os.rmdir(outdir)\n",
    "os.makedirs(outdir)\n",
    "\n",
    "\n",
    "dfs = [d for _,d in df[df['mcs_structural_cluster_number']>0].groupby('mcs_structural_cluster_number')]\n",
    "for dd in dfs:\n",
    "    dd = dd[pd.notna(dd['smiles'])]\n",
    "    # List of smiles\n",
    "    smiles_list = dd['smiles'].tolist()\n",
    "\n",
    "    # Smarts pattern for common substructure\n",
    "    pat = MolFromSmarts(dd['structural_pattern'].tolist()[0])\n",
    "\n",
    "    # Convert smiles to RDKit molecules\n",
    "    mols = [MolFromSmiles(smiles) for smiles in smiles_list]\n",
    "\n",
    "    highlight_list = [mol.GetSubstructMatch(pat) for mol in mols]\n",
    "    my_legend = ['%d'%m for m in dd['mcs_structural_cluster_number'].values]\n",
    "    highlist_list = highlight_list\n",
    "    \n",
    "    # [mol.GetSubstructMatch(pat) for mol in mols]\n",
    "    # Generate common substructure image\n",
    "    highlight_color = {i: (0, 1, 1) for mol in mols for i in mol.GetSubstructMatch(pat)}\n",
    "    image = MolsToGridImage(mols, molsPerRow=5, subImgSize=(300, 300), useSVG=True,maxMols=1000,\n",
    "                            legends=my_legend, highlightAtomLists=highlist_list,highlightAtomColors=[highlight_color]*len(mols))\n",
    "\n",
    "    # Display the image\n",
    "    outfile = os.path.join(outdir,'{}.svg'.format(dd['mcs_structural_cluster_number'].tolist()[0]))\n",
    "    with open(outfile,'w') as fid:\n",
    "        fid.write(image.data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "original_index = nx.get_node_attributes(G, 'original_index')\n",
    "mcs_structural_cluster_number = nx.get_node_attributes(G, 'mcs_structural_cluster_number')\n",
    "smiles = nx.get_node_attributes(G,smiles_col)\n",
    "\n",
    "df = pd.DataFrame({'smiles':smiles,'original_index': original_index, 'mcs_structural_cluster_number': mcs_structural_cluster_number})\n",
    "df = df[pd.notna(df['smiles'])]\n",
    "df = df.groupby('mcs_structural_cluster_number').filter(lambda x: len(x) >= 2)\n",
    "df.sort_values('mcs_structural_cluster_number', inplace=True)\n",
    "df = df[df['mcs_structural_cluster_number']>0]\n",
    "my_list = [MolFromSmiles(m) for m in df['smiles'].values]\n",
    "my_legend = ['%d'%m for m in df['mcs_structural_cluster_number'].values]\n",
    "image = MolsToGridImage(my_list, molsPerRow=10,maxMols=1000,legends=my_legend,useSVG=True)\n",
    "\n",
    "outfile = os.path.join(outdir,'AllStructuralClusters_massive.svg')\n",
    "with open(outfile,'w') as fid:\n",
    "    fid.write(image.data)\n",
    "\n",
    "\n",
    "shutil.make_archive('../data/structural_clusters_massive', 'zip', '.', outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "original_index = nx.get_node_attributes(G, 'original_index')\n",
    "mcs_structural_cluster_number = nx.get_node_attributes(G, 'mcs_structural_cluster_number')\n",
    "smiles = nx.get_node_attributes(G,smiles_col)\n",
    "node_id = {k:k for k in G.nodes()}\n",
    "\n",
    "df = pd.DataFrame({'node_id':node_id,'smiles':smiles,'original_index': original_index, 'mcs_structural_cluster_number': mcs_structural_cluster_number})\n",
    "df = df[pd.notna(df['smiles'])]\n",
    "df = df.groupby('mcs_structural_cluster_number').filter(lambda x: len(x) >= 2)\n",
    "df.sort_values('mcs_structural_cluster_number', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "dfs = [d for _,d in df.groupby('mcs_structural_cluster_number')]\n",
    "out = []\n",
    "for i,dd in enumerate(dfs):\n",
    "    nodes = dd['node_id'].tolist()\n",
    "    new_nodes = min_additional_subgraph(G, nodes)\n",
    "    mols = [MolFromSmiles(s) for s in dd['smiles'].tolist()]\n",
    "    res = rdFMCS.FindMCS(mols,timeout=120,ringMatchesRingOnly=True)\n",
    "    num_bonds = [m.GetNumBonds() for m in mols]\n",
    "    mcs = res.numBonds / np.min(num_bonds)\n",
    "    # len(n),dd.shape[0],n,sorted(dd['node_id'].tolist())\n",
    "    # dd['new_nodes'] = None\n",
    "    temp = pd.DataFrame()\n",
    "    temp['node_id'] = new_nodes \n",
    "    temp = pd.merge(temp,dd,on='node_id',how='outer')\n",
    "    temp['mcs'] = mcs\n",
    "    temp['mcs_structural_cluster_number'] = i\n",
    "    temp['structural_pattern'] = res.smartsString\n",
    "    # temp['mcs_structural_cluster_number'] = i\n",
    "    temp.drop(columns=['original_index'])\n",
    "    out.append(temp)\n",
    "\n",
    "\n",
    "df = pd.concat(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id = {k:k for k in G.nodes()}\n",
    "node_id = pd.Series(node_id)\n",
    "node_id = node_id.to_frame()\n",
    "node_id.columns = ['node_id']\n",
    "node_id = pd.merge(node_id,df,on='node_id',how='left')\n",
    "# node_id = node_id[['node_id','structural_pattern','mcs','mcs_structural_cluster_number']]\n",
    "node_id['structural_pattern'] = node_id['structural_pattern'].fillna('')\n",
    "node_id['mcs'] = node_id['mcs'].fillna(0)\n",
    "node_id['mcs_structural_cluster_number'] = node_id['mcs_structural_cluster_number'].fillna(-1)\n",
    "node_id['mcs_structural_cluster_number'] = node_id['mcs_structural_cluster_number'].astype(int)\n",
    "node_id['structural_pattern'] = node_id['structural_pattern'].astype(str)\n",
    "node_id['mcs'] = node_id['mcs'].astype(float)\n",
    "node_id\n",
    "\n",
    "# Add cluster labels to graph\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['structural_pattern'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_structural_pattern')\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['mcs'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_similarity')\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['mcs_structural_cluster_number'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_structural_cluster_number')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat(out)\n",
    "df['nl_spectrum'] = df.apply(lambda x: np.asarray([x['mdm_mz_vals'],x['mdm_i_vals']]),axis=1)\n",
    "\n",
    "df['sum_frag_intensity'] = df['mdm_i_vals'].apply(lambda x: np.sum(x))\n",
    "df['original_spectrum'] = df['nl_spectrum']#df.apply(lambda x: np.asarray([x['original_mz_vals'],x['original_i_vals']]),axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_files = merged_df.loc[merged_df['percent_greater'] < 40,'filename'].tolist()\n",
    "# print(df.shape[0])\n",
    "# df = df[df['filename'].isin(good_files)]\n",
    "# print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coisolated_precursor_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sum_frag_intensity']>0]\n",
    "df['num_mdm_frags'] = df['mdm_mz_vals'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_mdm_frags'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref,ref2 = wt.get_p2d2(deltas,mz_tol=mz_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dfs = wt.blink_score(df,ref,ref2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['rem_predicted_score','ref','query']\n",
    "nl_hits = pd.merge(out_dfs[3][cols],ref2[['original_p2d2_index']],left_on='ref',right_index=True)\n",
    "orig_hits = pd.merge(out_dfs[2][cols],ref[['original_p2d2_index']],left_on='ref',right_index=True)\n",
    "nl_hits.drop(columns=['ref'],inplace=True)\n",
    "orig_hits.drop(columns=['ref'],inplace=True)\n",
    "\n",
    "temp = pd.merge(nl_hits,orig_hits,on=['query','original_p2d2_index'],how='outer',suffixes=('_original_rem','_nl_rem'))\n",
    "\n",
    "temp['max_score'] = temp[['rem_predicted_score_original_rem','rem_predicted_score_nl_rem']].max(axis=1)\n",
    "temp['best_match_method'] = temp[['rem_predicted_score_original_rem','rem_predicted_score_nl_rem']].idxmax(axis=1)\n",
    "temp.sort_values('max_score',ascending=False,inplace=True)\n",
    "temp = temp[temp['max_score']>0.01]  #filter on score\n",
    "\n",
    "cols = ['name', 'inchi_key', 'smiles']\n",
    "\n",
    "temp = pd.merge(temp,df[['original_index','coisolated_precursor_count']].add_suffix('_query'),left_on='query',right_index=True)\n",
    "\n",
    "idx_isolated = (temp['coisolated_precursor_count_query']>1) & (temp['best_match_method']=='rem_predicted_score_original_rem')\n",
    "temp = temp[~idx_isolated] #filter on co-isolated precursor\n",
    "\n",
    "temp.sort_values('max_score',ascending=False,inplace=True)\n",
    "temp = temp.groupby('query').head(1)\n",
    "temp.reset_index(inplace=True,drop=True)\n",
    "\n",
    "cols = ['rem_predicted_score_original_rem', 'rem_predicted_score_nl_rem', 'coisolated_precursor_count_query']\n",
    "temp.drop(columns=cols,inplace=True)\n",
    "\n",
    "cols = ['name', 'inchi_key', 'smiles','formula','precursor_mz','original_p2d2_index']\n",
    "temp = pd.merge(temp,ref[cols],left_on='original_p2d2_index',right_on='original_p2d2_index',how='left')\n",
    "\n",
    "df = pd.merge(df,temp.add_suffix('_analog'),left_on='original_index',right_on='original_index_query_analog',how='left')\n",
    "# df.drop(columns=['original_index_query_analog','original_p2d2_index','query'],inplace=True)\n",
    "\n",
    "cols = ['original_index_query_analog','query_analog']\n",
    "df.drop(columns=cols,inplace=True)\n",
    "\n",
    "\n",
    "cols = ['score','matches','ref','query']\n",
    "nl_hits = pd.merge(out_dfs[1][cols],ref2[['original_p2d2_index']],left_on='ref',right_index=True)\n",
    "orig_hits = pd.merge(out_dfs[0][cols],ref[['original_p2d2_index']],left_on='ref',right_index=True)\n",
    "nl_hits.drop(columns=['ref'],inplace=True)\n",
    "orig_hits.drop(columns=['ref'],inplace=True)\n",
    "\n",
    "temp = pd.merge(nl_hits,orig_hits,on=['query','original_p2d2_index'],how='outer',suffixes=('_original','_nl'))\n",
    "\n",
    "temp['max_score'] = temp[['score_original','score_nl']].max(axis=1)\n",
    "temp['best_match_method'] = temp[['score_original','score_nl']].idxmax(axis=1)\n",
    "temp.sort_values('max_score',ascending=False,inplace=True)\n",
    "temp = temp[temp['max_score']>0.7]  #filter on score\n",
    "temp['max_matches'] = 0\n",
    "idx = temp['best_match_method']=='score_original'\n",
    "temp.loc[idx,'max_matches'] = temp.loc[idx,'matches_original']\n",
    "idx = temp['best_match_method']=='score_nl'\n",
    "temp.loc[idx,'max_matches'] = temp.loc[idx,'matches_nl']\n",
    "temp = temp[temp['max_matches']>=3]  #filter on matches\n",
    "\n",
    "cols = ['score_original','matches_original', 'score_nl', 'matches_nl']\n",
    "temp.drop(columns=cols,inplace=True)\n",
    "temp = pd.merge(temp,df[['original_index','precursor_mz','coisolated_precursor_count']].add_suffix('_query'),left_on='query',right_index=True)\n",
    "\n",
    "idx_isolated = (temp['coisolated_precursor_count_query']>1) & (temp['best_match_method']=='score_original')\n",
    "temp = temp[~idx_isolated] #filter on isolated precursor\n",
    "\n",
    "cols = ['name', 'inchi_key', 'smiles','formula','precursor_mz','original_p2d2_index']\n",
    "temp = pd.merge(temp,ref[cols],left_on='original_p2d2_index',right_on='original_p2d2_index',how='left')\n",
    "\n",
    "idx_precursor = (abs(temp['precursor_mz_query']-temp['precursor_mz'])<mz_tol)\n",
    "temp = temp[idx_precursor] #filter on precursor m/z\n",
    "\n",
    "temp.sort_values('max_score',ascending=False,inplace=True)\n",
    "\n",
    "temp = temp.groupby('query').head(1)\n",
    "temp.reset_index(inplace=True,drop=True)\n",
    "\n",
    "df = pd.merge(df,temp.add_suffix('_identity'),left_on='original_index',right_on='original_index_query_identity',how='left')\n",
    "# df.drop(columns=['original_index_query_analog','original_p2d2_index','query'],inplace=True)\n",
    "\n",
    "cols = ['original_index_query_identity',\n",
    "        'query_identity',\n",
    "        'precursor_mz_query_identity',\n",
    "        'coisolated_precursor_count_query_identity']\n",
    "df.drop(columns=cols,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['original_p2d2_index_analog','nl_spectrum']\n",
    "# cols = ['original_p2d2_index_identity','nl_spectrum']\n",
    "# cols = ['original_p2d2_index_analog','spectrum']\n",
    "cols = ['original_p2d2_index','spectrum']\n",
    "df = pd.merge(df,ref[cols].add_suffix('_ref_identity'),left_on='original_p2d2_index_identity',right_on='original_p2d2_index_ref_identity',how='left')\n",
    "df = pd.merge(df,ref[cols].add_suffix('_ref_analog'),left_on='original_p2d2_index_analog',right_on='original_p2d2_index_ref_analog',how='left')\n",
    "drop = ['original_p2d2_index_ref_identity','original_p2d2_index_ref_analog']\n",
    "df.drop(columns=drop,inplace=True)\n",
    "cols = ['original_p2d2_index','nl_spectrum']\n",
    "df = pd.merge(df,ref2[cols].add_suffix('_ref_identity'),left_on='original_p2d2_index_identity',right_on='original_p2d2_index_ref_identity',how='left')\n",
    "df = pd.merge(df,ref2[cols].add_suffix('_ref_analog'),left_on='original_p2d2_index_analog',right_on='original_p2d2_index_ref_analog',how='left')\n",
    "drop = ['original_p2d2_index_ref_identity','original_p2d2_index_ref_analog']\n",
    "df.drop(columns=drop,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df['predicted_formula'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values('num_mdm_frags',ascending=False,inplace=True)\n",
    "# df.drop_duplicates('predicted_formula',inplace=True)\n",
    "# df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[pd.notna(df['predicted_formula'])]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wt.eliminate_duplicate_spectra(out,deltas,mz_tol=mz_tol,\n",
    "                                similarity_cutoff=similarity_cutoff,\n",
    "                                min_intensity_ratio=min_intensity_ratio)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coisolated_precursor_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# rem_df = wt.do_remblink_networking(df,df,spectra_attr='buddy_spectrum')\n",
    "rem_df = wt.do_remblink_networking(df,df,spectra_attr='nl_spectrum')\n",
    "cols = ['ref','query','rem_predicted_score']\n",
    "rem_df = rem_df[cols]\n",
    "rem_df = rem_df[rem_df['rem_predicted_score']>0.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_props = wt.get_formula_props(df,formula_key='predicted_formula')\n",
    "df = pd.merge(df,formula_props,left_on='predicted_formula',right_on='formula',how='left')\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = pd.read_parquet('/global/cfs/cdirs/metatlas/projects/rawdata_for_scn/20181217_KBL_TM_Lakes_GEODES_All3_QE-HF_C18_USDAY46918_NEG_MSMS_68_GEO-TB-36-F_1_Rg80to1200-CE102040-0-1-S1_Run246.parquet')\n",
    "# p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOM net: (6283, 13884)\n",
    "# Plant net: (3424, 4873)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# # Create the graph from the similarity matrix\n",
    "G = nx.from_pandas_edgelist(rem_df,source='ref',target='query',edge_attr='rem_predicted_score')\n",
    "# (similarity_matrix > similarity_cutoff)\n",
    "# # Add node data from ms2_df to G\n",
    "cols = list(set([c for c in df.columns if not 'spect' in c]) - set(['obs','coisolated_precursor_mz_list','mol','filename', 'basename', 'experiment']))\n",
    "cols = [c for c in cols if not 'mdm_' in c]\n",
    "cols = [c for c in cols if not 'original_' in c]\n",
    "# cols = cols + ['stable']\n",
    "node_data = df[cols].to_dict(orient='index')\n",
    "\n",
    "nx.set_node_attributes(G, node_data)\n",
    "            \n",
    "# print(len(G.nodes))\n",
    "# print(len(G.edges))\n",
    "\n",
    "# # Remove self-loops\n",
    "G.remove_edges_from([(u, v) for u, v in G.edges() if u == v])         \n",
    "\n",
    "# Remove isolates\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "print('nodes',len(G.nodes))\n",
    "print('edges',len(G.edges))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "250000**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_sum_frag_intensity'] = np.log10(df['sum_frag_intensity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = (df['isin_fticr_formula'] == True) & (df['predicted_formula'].str.contains('S'))\n",
    "idx2 = (df['isin_fticr_formula'] == False) & (df['predicted_formula'].str.contains('S'))\n",
    "out = []\n",
    "out.append((sum(idx1),sum(idx2),sum(idx1)+sum(idx2)))\n",
    "\n",
    "idx1 = (df['isin_fticr_formula'] == True) & (df['predicted_formula'].str.contains('N'))\n",
    "idx2 = (df['isin_fticr_formula'] == False) & (df['predicted_formula'].str.contains('N'))\n",
    "\n",
    "out.append((sum(idx1),sum(idx2),sum(idx1)+sum(idx2)))\n",
    "\n",
    "idx1 = (df['isin_fticr_formula'] == True) & (df['predicted_formula'].str.contains('P'))\n",
    "idx2 = (df['isin_fticr_formula'] == False) & (df['predicted_formula'].str.contains('P'))\n",
    "\n",
    "out.append((sum(idx1),sum(idx2),sum(idx1)+sum(idx2)))\n",
    "\n",
    "idx1 = (df['isin_fticr_formula'] == True) & (~df['predicted_formula'].str.contains('P|N|S'))\n",
    "idx2 = (df['isin_fticr_formula'] == False) & (~df['predicted_formula'].str.contains('P|N|S'))\n",
    "\n",
    "out.append((sum(idx1),sum(idx2),sum(idx1)+sum(idx2)))\n",
    "out = pd.DataFrame(out,columns=['FTICR','Not FTICR','Total'],index=['S','N','P','CHO'])\n",
    "out['FTICR'] = out['FTICR'] / out['Total']\n",
    "out['Not FTICR'] = out['Not FTICR'] / out['Total']\n",
    "out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = df.dtypes\n",
    "print(column_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARE WE MISSING ANY FTICR FORMULA??????\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2,ncols=2,figsize=(10,6 ))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Filter rows where isin_fticr_formula is True\n",
    "df_true = df[df['isin_fticr_formula']]\n",
    "\n",
    "# Filter rows where isin_fticr_formula is False\n",
    "df_false = df[~df['isin_fticr_formula']]\n",
    "\n",
    "# Plot histogram for isin_fticr_formula=True\n",
    "counter = 0\n",
    "df['log_sum_frag_intensity'] = np.log10(df['sum_frag_intensity'])\n",
    "cols = ['coisolated_precursor_count', 'num_mdm_frags','mass_error','log_sum_frag_intensity']\n",
    "for c in cols:\n",
    "    ax[counter].hist(df_true[c], bins=15, alpha=0.5, density=False,label='isin_fticr_formula=True')\n",
    "\n",
    "    # Plot histogram for isin_fticr_formula=False\n",
    "    ax[counter].hist(df_false[c], bins=15, alpha=0.5,density=False, label='isin_fticr_formula=False')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax[counter].set_xlabel(c)\n",
    "    ax[counter].set_ylabel('Frequency')\n",
    "    ax[counter].legend()\n",
    "    counter += 1\n",
    "plt.tight_layout()\n",
    "# ax.set_xlim(-0.001,0.001)\n",
    "# Add legend\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['environment_type:aquatic', 'environment_type:soil',\n",
    "       'environment_type:wetland', 'extraction_solvent:chloroform',\n",
    "       'extraction_solvent:methanol-water', 'extraction_solvent:water',\n",
    "       'ppl_extracted:False', 'ppl_extracted:True',\n",
    "       'instrument_type:12 Tesla FT-ICR-MS',\n",
    "       'instrument_type:15 Tesla FT-ICR-MS', 'mass_range:100-900',\n",
    "       'mass_range:125-2000', 'mass_range:150-2000', 'mass_range:200-1200']\n",
    "formula_df.loc[~formula_df['formula'].isin(df['predicted_formula']),cols].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_complex_attributes(G):\n",
    "    for node, data in G.nodes(data=True):\n",
    "        complex_attributes = [key for key, value in data.items() if isinstance(value, (list, set, dict,object))]\n",
    "        for attribute in complex_attributes:\n",
    "            del G.nodes[node][attribute]\n",
    "    return G\n",
    "G = remove_complex_attributes(G) #it removes everything.\n",
    "nx.write_graphml(G, 'eom-net-0p1-cutoff-cho.graphml')\n",
    "# nx.write_graphml(G, 'plantmasst_0p1.graphml')\n",
    "# 250000**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['buddy'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
