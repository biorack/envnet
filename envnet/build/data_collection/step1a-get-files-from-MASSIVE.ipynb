{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import os\n",
    "\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dirs = ['/pscratch/sd/b/bpb/massive',\n",
    "              '/global/cfs/cdirs/metatlas/projects/rawdata_for_scn',\n",
    "              '/global/cfs/cdirs/metatlas/projects/massive_data_for_scn']\n",
    "\n",
    "\n",
    "def get_files(main_dir):\n",
    "    mzml_files = glob.glob(main_dir + '/**/*.mzML', recursive=True)\n",
    "    mzxml_files = glob.glob(main_dir + '/**/*.mzXML', recursive=True)\n",
    "    hdf5_files = glob.glob(main_dir + '/**/*.h5', recursive=True)\n",
    "    buddy_mdm_files = glob.glob(main_dir + '/**/*.parquet', recursive=True)\n",
    "    buddy_failed_mdm_files = glob.glob(main_dir + '/**/*.parquet-failed', recursive=True)\n",
    "\n",
    "    df_mzml = pd.DataFrame({'mzml': mzml_files})\n",
    "    df_mzml['no_extension'] = df_mzml['mzml'].apply(lambda x: x.replace('.mzML', ''))\n",
    "    df_mzml.set_index('no_extension', inplace=True)\n",
    "    df_mzxml = pd.DataFrame({'mzxml': mzxml_files})\n",
    "    df_mzxml['no_extension'] = df_mzxml['mzxml'].apply(lambda x: x.replace('.mzXML', ''))\n",
    "    df_mzxml.set_index('no_extension', inplace=True)\n",
    "    df_h5 = pd.DataFrame({'h5': hdf5_files})\n",
    "    df_h5['no_extension'] = df_h5['h5'].apply(lambda x: x.replace('.h5', ''))\n",
    "    df_h5.set_index('no_extension', inplace=True)\n",
    "    df_buddy = pd.DataFrame({'buddy': buddy_mdm_files})\n",
    "    df_buddy['no_extension'] = df_buddy['buddy'].apply(lambda x: x.replace('.parquet', ''))\n",
    "    df_buddy.set_index('no_extension', inplace=True)\n",
    "    df_buddy_failed = pd.DataFrame({'buddy_failed': buddy_failed_mdm_files})\n",
    "    df_buddy_failed['no_extension'] = df_buddy_failed['buddy_failed'].apply(lambda x: x.replace('.parquet-failed', ''))\n",
    "    df_buddy_failed.set_index('no_extension', inplace=True)\n",
    "\n",
    "    df = df_mzml.join(df_mzxml, how='outer').join(df_h5, how='outer').join(df_buddy, how='outer').join(df_buddy_failed, how='outer')\n",
    "    df['data_dir'] = main_dir\n",
    "    return df\n",
    "\n",
    "def get_files_from_dirs(data_dirs):\n",
    "    out = []\n",
    "    for data_dir in data_dirs:\n",
    "        out.append(get_files(data_dir))\n",
    "    if len(data_dirs)>1:\n",
    "        return pd.concat(out)\n",
    "    else:\n",
    "        return out[0]\n",
    "\n",
    "done_df = get_files_from_dirs(data_dirs)\n",
    "cols = ['h5','buddy','data_dir']\n",
    "done_df = done_df[cols]\n",
    "\n",
    "pattern = r'(?<=/)(MSV.*?)(?=/)'\n",
    "a = done_df.copy().index.str.extract(pattern)\n",
    "done_df['massive_id'] = a[0].tolist()\n",
    "\n",
    "done_df.reset_index(inplace=True,drop=False)\n",
    "print(done_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import os\n",
    "import re\n",
    "\n",
    "\"\"\"\n",
    "MIT license: 2017 - Jwely\n",
    "\n",
    "Example usage:\n",
    "``` python\n",
    "import ftplib\n",
    "ftp = ftplib.FTP(mysite, username, password)\n",
    "download_ftp_tree(ftp, remote_dir, local_dir)\n",
    "```\n",
    "\n",
    "The code above will look for a directory called \"remote_dir\" on the ftp host, and then duplicate the\n",
    "directory and its entire contents into the \"local_dir\".\n",
    "\n",
    "*** Note that if wget is an option, I recommend using that instead ***\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def _is_ftp_dir(ftp_handle, name, guess_by_extension=True):\n",
    "    \"\"\" simply determines if an item listed on the ftp server is a valid directory or not \"\"\"\n",
    "\n",
    "    # if the name has a \".\" in the fourth to last position, its probably a file extension\n",
    "    # this is MUCH faster than trying to set every file to a working directory, and will work 99% of time.\n",
    "    if guess_by_extension is True:\n",
    "        if len(name) >= 6:\n",
    "            if name[-4] == '.': #.raw\n",
    "                return False\n",
    "            elif name[-5] == '.': #.mzml\n",
    "                return False\n",
    "            elif name[-6] == '.': #.mzxml\n",
    "                return False\n",
    "\n",
    "    original_cwd = ftp_handle.pwd()  # remember the current working directory\n",
    "    try:\n",
    "        # print(name,original_cwd)\n",
    "        ftp_handle.cwd(name)  # try to set directory to new name\n",
    "        ftp_handle.cwd(original_cwd)  # set it back to what it was\n",
    "        return True\n",
    "\n",
    "    except ftplib.error_perm as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "def _make_parent_dir(fpath):\n",
    "    \"\"\" ensures the parent directory of a filepath exists \"\"\"\n",
    "    dirname = os.path.dirname(fpath)\n",
    "    while not os.path.exists(dirname):\n",
    "        try:\n",
    "            os.makedirs(dirname)\n",
    "            print(\"created {0}\".format(dirname))\n",
    "        except OSError as e:\n",
    "            print(e)\n",
    "            _make_parent_dir(dirname)\n",
    "\n",
    "\n",
    "def _download_ftp_file(ftp_handle, name, dest, overwrite):\n",
    "    \"\"\" downloads a single file from an ftp server \"\"\"\n",
    "    _make_parent_dir(dest.lstrip(\"/\"))\n",
    "    if _file_name_match_patern(pattern, name):\n",
    "        if not os.path.exists(dest) or overwrite is True:\n",
    "            try:\n",
    "                s = ftp.size(name)   # Get size of file\n",
    "                print(s)\n",
    "                if (s<500e6) & (s>1e6):\n",
    "                    try:\n",
    "                        with open(dest, 'wb') as f:\n",
    "                            ftp_handle.retrbinary(\"RETR {0}\".format(name), f.write)\n",
    "                        print(\"downloaded: {0}\".format(dest))\n",
    "                    except:\n",
    "                        with open(dest, 'wb') as f: pass\n",
    "                        print(\"FAILED: {0} is too big or too small\".format(dest))\n",
    "                else:\n",
    "                    with open(dest, 'wb') as f: pass\n",
    "                    print(\"FAILED: {0} is too big or too small\".format(dest))\n",
    "            except FileNotFoundError:\n",
    "                print(\"FAILED: {0}\".format(dest))\n",
    "        else:\n",
    "            print(\"already exists: {0}\".format(dest))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def _file_name_match_patern(pattern, name):\n",
    "    \"\"\" returns True if filename matches the pattern\"\"\"\n",
    "    if pattern is None:\n",
    "        return True\n",
    "    else:\n",
    "        pat_match = bool(re.match(pattern, name,re.IGNORECASE))\n",
    "        return pat_match\n",
    "\n",
    "# def _check_name_size(name, size):\n",
    "#     # name = '/v01/MSV000088823/peak/neg-Mode_MS1/Lab_01/DOM_Interlab-LCMS_Lab1_A5M_Neg_MS1_rep3.mzML'\n",
    "#     s = ftp.size(name)   # Get size of file\n",
    "#     return s\n",
    "\n",
    "def _mirror_ftp_dir(ftp_handle, name, overwrite, guess_by_extension, pattern):\n",
    "    \"\"\" replicates a directory on an ftp server recursively \"\"\"\n",
    "    for item in ftp_handle.nlst(name):\n",
    "        if _is_ftp_dir(ftp_handle, item, guess_by_extension):\n",
    "            _mirror_ftp_dir(ftp_handle, item, overwrite, guess_by_extension, pattern)\n",
    "        else:\n",
    "            _download_ftp_file(ftp_handle, item, item, overwrite)\n",
    "            # else:\n",
    "            #     # quietly skip the file\n",
    "            #     pass\n",
    "\n",
    "\n",
    "def download_ftp_tree(ftp_handle, path, destination, pattern=None, overwrite=False, guess_by_extension=True):\n",
    "    \"\"\"\n",
    "    Downloads an entire directory tree from an ftp server to the local destination\n",
    "    :param ftp_handle: an authenticated ftplib.FTP instance\n",
    "    :param path: the folder on the ftp server to download\n",
    "    :param destination: the local directory to store the copied folder\n",
    "    :param pattern: Python regex pattern, only files that match this pattern will be downloaded.\n",
    "    :param overwrite: set to True to force re-download of all files, even if they appear to exist already\n",
    "    :param guess_by_extension: It takes a while to explicitly check if every item is a directory or a file.\n",
    "        if this flag is set to True, it will assume any file ending with a three character extension \".???\" is\n",
    "        a file and not a directory. Set to False if some folders may have a \".\" in their names -4th position.\n",
    "    \"\"\"\n",
    "    path = path.lstrip(\"/\")\n",
    "    original_directory = os.getcwd()  # remember working directory before function is executed\n",
    "    os.chdir(destination)  # change working directory to ftp mirror directory\n",
    "\n",
    "    _mirror_ftp_dir(\n",
    "        ftp_handle,\n",
    "        path,\n",
    "        pattern=pattern,\n",
    "        overwrite=overwrite,\n",
    "        guess_by_extension=guess_by_extension)\n",
    "\n",
    "    os.chdir(original_directory)  # reset working directory to what it was before function exec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_ftp_directory_structure(host, username='', password=''):\n",
    "    # Connect to the FTP server\n",
    "    ftp = ftplib.FTP(host)\n",
    "    ftp.login(username, password)\n",
    "\n",
    "    # Get the directory listing\n",
    "    listing = []\n",
    "    ftp.retrlines('LIST', listing.append)\n",
    "\n",
    "    # Parse the directory listing into a dataframe\n",
    "    df = pd.DataFrame([line.split() for line in listing], columns=['permissions', 'links', 'owner', 'group', 'size', 'month', 'day', 'time', 'name'])\n",
    "    out = []\n",
    "    # Iterate over the directories and get the subdirectory listing\n",
    "    for index, row in df.iterrows():\n",
    "        if row['permissions'][0] == 'd':\n",
    "            subdirectory = row['name']\n",
    "            sublisting = []\n",
    "            ftp.retrlines(f'LIST {subdirectory}', sublisting.append)\n",
    "            subdf = pd.DataFrame([line.split() for line in sublisting], columns=['permissions', 'links', 'owner', 'group', 'size', 'month', 'day', 'time', 'name'])\n",
    "            subdf['subdirectory'] = row['name']\n",
    "            # df.at[index, 'subdirectory'] = subdf\n",
    "            out.append(subdf)\n",
    "            \n",
    "    \n",
    "    # Close the FTP connection\n",
    "    ftp.quit()\n",
    "    df = pd.concat(out)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Specify the FTP host\n",
    "host = 'massive.ucsd.edu'\n",
    "\n",
    "# Get the directory structure as a dataframe\n",
    "df = get_ftp_directory_structure(host)\n",
    "\n",
    "# Print the dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom_samples = pd.read_csv('/global/homes/b/bpb/repos/scndb/data/dom_public_datasets.csv',usecols=['dataset'])\n",
    "# dom_samples = dom_samples[~dom_samples['dataset'].isin(done_df['massive_id'])]\n",
    "\n",
    "# bad_massive = ['MSV000092338','MSV000093271','MSV000092599','MSV000093514','MSV000092622','MSV000092604','MSV000092520']\n",
    "df = df[df['name'].isin(dom_samples['dataset'])]\n",
    "# MSV000082082\n",
    "# drop = ['MSV000089481']  # These two worked: 'MSV000082082','MSV000089591'\n",
    "# df = df[~df['name'].isin(drop)]\n",
    "# d = ['MSV000089481']\n",
    "# df = df[df['name'].isin(d)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_samples = pd.read_csv('/global/cfs/cdirs/metatlas/projects/carbon_network/all_sampleinformation.tsv',sep='\\t',usecols=['ATTRIBUTE_DatasetAccession','filename','SampleType'])\n",
    "plant_samples = plant_samples[~plant_samples['filename'].str.contains('qc',case=False)]\n",
    "plant_samples = plant_samples[~plant_samples['filename'].str.contains('blank',case=False)]\n",
    "plant_samples = plant_samples[plant_samples['SampleType']=='plant']\n",
    "\n",
    "\n",
    "df = df[df['name'].isin(plant_samples['ATTRIBUTE_DatasetAccession'])]\n",
    "df = df[~df['name'].isin(done_df['massive_id'])]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dom_samples[dom_samples['dataset']=='MSV000082082']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Wait for 2 seconds\n",
    "\n",
    "# FILEPATH: /global/homes/b/bpb/repos/scndb/build/Get_MASSIVE_LIST-of-IDs_or_MIRROR.ipynb\n",
    "# Example usage mirroring all jpg files in an FTP directory tree.\n",
    "host = \"massive.ucsd.edu\"\n",
    "username = \"\"\n",
    "password = \"\"\n",
    "ftp = ftplib.FTP(host)\n",
    "ftp.login(username, password)\n",
    "for i,row in df.iterrows():\n",
    "    remote_dir = f\"/{row['subdirectory']}/{row['name']}\"\n",
    "    print(remote_dir)\n",
    "    local_dir = \"/pscratch/sd/b/bpb/massive\"\n",
    "    pattern = \".*\\.mz[X]*ML$\"\n",
    "    # ftp = ftplib.FTP(mysite, username, password)\n",
    "\n",
    "    download_ftp_tree(ftp, remote_dir, local_dir, pattern=pattern, overwrite=False, guess_by_extension=True)\n",
    "    # Wait for 2 seconds\n",
    "    print('waiting...')\n",
    "    time.sleep(1)\n",
    "\n",
    "ftp.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "my_dir = '/pscratch/sd/b/bpb/massive'\n",
    "\n",
    "# Change permissions\n",
    "subprocess.run(['chmod', '-R', '770', my_dir])\n",
    "\n",
    "# Change group\n",
    "subprocess.run(['chgrp', '-R', 'metatlas', my_dir])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 289.286376953125%208068.0%5Cn295.5452880859375%2022507.0%5Cn298.4896240234375%203925.0%5Cn317.324951171875%2018742.0%5Cn319.65594482421875%208604.0%5Cn324.482421875%208041.0%5Cn325.3162841796875%209738.0%5Cn339.7894287109375%2016145.0%5Cn343.947021484375%2018094.0%5Cn347.0205078125%2013981.0%5Cn347.91339111328125%206765.0%5Cn361.147705078125%2011763.0%5Cn361.8443603515625%2024296.0%5Cn364.23272705078125%202346.0%5Cn364.858154296875%2010782.0%5Cn365.84588623046875%2010242.0%5Cn368.2216796875%2012761.0%5Cn368.9656982421875%2019147.0%5Cn375.06951904296875%2015644.0%5Cn375.751953125%2025393.0%5Cn382.75054931640625%2012765.0%5Cn384.19708251953125%2017912.0%5Cn390.57421875%207993.0%5Cn394.0491943359375%2016135.0%5Cn397.10626220703125%2013986.0%5Cn404.42071533203125%2012326.0%5Cn411.09271240234375%202348.0%5Cn413.7845458984375%208715.0%5Cn427.6673583984375%2068137.0%5Cn436.1927490234375%2014879.0%5Cn443.26611328125%2044427.0%5Cn446.26727294921875%2023472.0%5Cn447.74749755859375%2029292.0%5Cn455.25%2070939.0%5Cn456.1075439453125%20105392.0%5Cn456.8221435546875%203.0%5Cn457.543212890625%2012862.0%5Cn464.28546142578125%208617.0%5Cn469.872314453125%2087594.0%5Cn471.06219482421875%2031482.0%5Cn475.25732421875%2015449.0%5Cn476.14361572265625%2023143.0%5Cn476.97515869140625%2028430.0%5Cn478.89111328125%2027890.0%5Cn479.9759521484375%2033235.0%5Cn483.242431640625%2013564.0%5Cn487.21038818359375%2032885.0%5Cn488.16015625%2020786.0%5Cn491.19195556640625%2055073.0%5Cn494.27960205078125%207435.0%5Cn495.65399169921875%2032208.0%5Cn498.4129638671875%2011684.0%5Cn503.0281982421875%2030643.0%5Cn503.699951171875%202.0%5Cn504.34454345703125%2036421.0%5Cn505.154541015625%209667.0%5Cn510.176513671875%2038891.0%5Cn512.168701171875%2010175.0%5Cn513.265380859375%2016524.0%5Cn514.9573974609375%2011384.0%5Cn515.9228515625%2078764.0%5Cn520.973388671875%2028857.0%5Cn521.82373046875%205810.0%5Cn523.1689453125%2058926.0%5Cn529.036865234375%2020722.0%5Cn530.9912109375%2031845.0%5Cn532.376708984375%203005.0%5Cn534.5751953125%2012906.0%5Cn538.003173828125%20220949.0%5Cn539.2177734375%20272296.0%5Cn540.6728515625%2043876.0%5Cn548.0614013671875%2013655.0%5Cn554.117431640625%2076225.0%5Cn556.0303955078125%20214421.0%5Cn557.288818359375%2052970.0%5Cn557.99609375%206202.0%5Cn559.9422607421875%2018112.0%5Cn561.3287353515625%2014656.0%5Cn564.123046875%2025971.0%5Cn564.94873046875%2034630.0%5Cn566.43994140625%2035564.0%5Cn571.333740234375%2061305.0%5Cn572.04736328125%2017235.0%5Cn575.21923828125%2042127.0%5Cn575.888916015625%206.0%5Cn577.1029052734375%2029550.0%5Cn579.6458740234375%207151.0%5Cn580.942626953125%2017609.0%5Cn582.110107421875%20102075.0%5Cn583.458984375%2010113.0%5Cn585.237060546875%2036774.0%5Cn598.1724853515625%2026085.0%5Cn599.352783203125%20764523.0%5Cn600.3828125%20114267.0%5Cn601.066650390625%204.0%5Cn602.267578125%2027144.0%5Cn609.302001953125%2010247.0%5Cn613.415771484375%208621.0%5Cn622.208984375%2023787.0%5Cn623.023193359375%2063940.0%5Cn623.991455078125%2019154.0%5Cn625.2161865234375%2023050.0%5Cn638.299560546875%2012481.0%5Cn640.265625%2017392.0%5Cn641.235107421875%2065873.0%5Cn646.095947265625%208409.0%5Cn649.277099609375%205446.0%5Cn651.526611328125%2017521.0%5Cn657.12890625%2012911.0%5Cn658.094970703125%2014824.0%5Cn659.4208984375%2041969.0%5Cn663.3876953125%2018284.0%5Cn668.33251953125%2065700.0%5Cn669.357177734375%205671.0%5Cn680.2197265625%2044374.0%5Cn681.98779296875%2024446.0%5Cn685.957763671875%2019166.0%5Cn691.648681640625%2029177.0%5Cn693.225830078125%2033545.0%5Cn694.307861328125%2022539.0%5Cn696.3323974609375%20121211.0%5Cn697.1278076171875%209503.0%5Cn709.4644775390625%2020171.0%5Cn710.79541015625%2022346.0%5Cn711.744873046875%2032675.0%5Cn714.07177734375%2050487.0%5Cn715.5789794921875%2054567.0%5Cn716.216552734375%208.0%5Cn723.267822265625%2014415.0%5Cn724.0819091796875%2088510.0%5Cn725.4888916015625%208470.0%5Cn728.35205078125%2021518.0%5Cn735.806396484375%2052022.0%5Cn738.3466796875%202697.0%5Cn744.365234375%2016205.0%5Cn747.4560546875%2019268.0%5Cn753.271240234375%2014114.0%5Cn761.609130859375%2012373.0%5Cn764.462158203125%2019876.0%5Cn765.280029296875%2018361.0%5Cn769.275634765625%2041999.0%5Cn770.32861328125%2016548.0%5Cn771.3863525390625%2013776.0%5Cn787.4326171875%2033003.0%5Cn796.1395263671875%209637.0%5Cn797.2327880859375%2011322.0%5Cn806.556884765625%2018639.0%5Cn808.4423828125%206355.0%5Cn811.6373291015625%2014687.0%5Cn812.300048828125%209904.0%5Cn813.1492919921875%2015959.0%5Cn817.21923828125%207640.0%5Cn820.2740478515625%206246.0%5Cn821.2882080078125%2015591.0%5Cn823.361328125%2013693.0%5Cn824.6182861328125%206895.0%5Cn828.5174560546875%2032132.0%5Cn830.4093017578125%20102583.0%5Cn831.3067626953125%2065294.0%5Cn832.10546875%209727.0%5Cn833.1845703125%204115.0%5Cn835.212890625%207606.0%5Cn836.0782470703125%208740.0%5Cn838.5186767578125%2026160.0%5Cn839.455810546875%2072006.0%5Cn845.6129150390625%2021577.0%5Cn847.43359375%20196462.0%5Cn848.1258544921875%2039637.0%5Cn851.380859375%20246170.0%5Cn852.37060546875%20276882.0%5Cn853.2705078125%2044216.0%5Cn865.597900390625%2044697.0%5Cn866.295654296875%20111012.0%5Cn867.1904296875%204120.0%5Cn868.3721923828125%2078023.0%5Cn869.3311767578125%208584.0%5Cn871.5570068359375%205374.0%5Cn877.137451171875%2030131.0%5Cn880.216552734375%205692.0%5Cn883.4422607421875%2049241.0%5Cn884.216552734375%208.0%5Cn888.1671142578125%2041037.0%5Cn889.282958984375%2024795.0%5Cn892.1278076171875%2014925.0%5Cn893.4678955078125%2023506.0%5Cn895.607421875%2013123.0%5Cn899.0101318359375%2028633.0%5Cn901.3511962890625%2013472.0%5Cn902.3255615234375%203774.0%5Cn909.4244384765625%20244136.0%5Cn910.515380859375%2043770.0%5Cn911.5263671875%2015208.0%5Cn914.3089599609375%206532.0%5Cn915.2177734375%2028455.0%5Cn918.6661376953125%205610.0%5Cn919.396240234375%2085829.0%5Cn920.066650390625%203.0%5Cn921.1239013671875%2016163.0%5Cn922.2056884765625%2037863.0%5Cn925.063720703125%2043395.0%5Cn931.1328125%2061732.0%5Cn932.3519287109375%20136657.0%5Cn933.5240478515625%2025202.0%5Cn935.4932861328125%2033896.0%5Cn936.552001953125%20103130.0%5Cn937.588623046875%2067605.0%5Cn938.4710693359375%2035379.0%5Cn939.617919921875%2077289.0%5Cn946.2578125%2038584.0%5Cn949.3702392578125%2085420.0%5Cn950.2845458984375%205976.0%5Cn951.5517578125%2029995.0%5Cn953.3966064453125%20545281.0%5Cn954.4915771484375%20123937.0%5Cn963.686767578125%20261578.0%5Cn964.524658203125%20318164.0%5Cn965.192138671875%20124405.0%5Cn982.221923828125%2027147.0\n",
    "\n",
    "spectrum = \"\"\"54.0348\t5\n",
    "58.0297\t2\n",
    "68.0504\t2\n",
    "81.0455\t100\n",
    "95.061\t6\n",
    "138.0663\t70\n",
    "156.0769\t10\"\"\"\n",
    "\n",
    "url = f'https://fasst.gnps2.org/fastsearch/?usi1=None&precursor_mz=981.54&charge=1&library_select=gnpslibrary&analog_select=No&delta_mass_below=130&delta_mass_above=200&pm_tolerance=0.001&fragment_tolerance=0.01&cosine_threshold=0.7&use_peaks=1#%7B%22peaks%22%3A%20%22{spectrum}%22%7D'\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "def query_fasst_peaks(precursor_mz, peaks, database, serverurl=\"https://fasst.gnps2.org/\", analog=False, precursor_mz_tol=0.05, fragment_mz_tol=0.05, min_cos=0.7):\n",
    "    spectrum_query = {\n",
    "        \"peaks\": peaks,\n",
    "        \"precursor_mz\": precursor_mz\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"query_spectrum\": json.dumps(spectrum_query),\n",
    "        \"library\": database,\n",
    "        \"analog\": \"Yes\" if analog else \"No\",\n",
    "        \"pm_tolerance\": precursor_mz_tol,\n",
    "        \"fragment_tolerance\": fragment_mz_tol,\n",
    "        \"cosine_threshold\": min_cos,\n",
    "    }\n",
    "\n",
    "    r = requests.post(serverurl + \"search\", data=params, timeout=50)\n",
    "\n",
    "    r.raise_for_status()\n",
    "\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "\n",
    "database = \"gnpsdata_index\"\n",
    "# database = \"gnpslibrary\"\n",
    "\n",
    "spectrum = \"\"\"54.0348   5\n",
    "58.0297 2\n",
    "68.0504 2\n",
    "81.0455 100\n",
    "95.061  6\n",
    "138.0663    70\n",
    "156.0769    10\"\"\"\n",
    "spectrum = spectrum.split('\\n')\n",
    "spectrum = [x.split() for x in spectrum]\n",
    "\n",
    "spectrum = [[float(x[0]), float(x[1])] for x in spectrum]\n",
    "precursor = 156.0769\n",
    "\n",
    "\n",
    "# results = query_fasst_peaks(json_spectrum[\"precursor_mz\"], json_spectrum[\"peaks\"], database)\n",
    "results = query_fasst_peaks(precursor, spectrum, database)\n",
    "\n",
    "results = pd.DataFrame(results['results'])\n",
    "results = results[abs(results['Delta Mass'])<0.01]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spectrum = \"\"\"54.0348   5\n",
    "58.0297 2\n",
    "68.0504 2\n",
    "81.0455 100\n",
    "95.061  6\n",
    "138.0663    70\n",
    "156.0769    10\"\"\"\n",
    "spectrum = spectrum.split('\\n')\n",
    "spectrum = [x.split() for x in spectrum]\n",
    "spectrum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
