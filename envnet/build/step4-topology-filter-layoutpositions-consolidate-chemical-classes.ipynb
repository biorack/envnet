{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2023.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "sys.path.insert(0,'/global/homes/b/bpb/repos/blink')\n",
    "import blink\n",
    "sys.path.insert(0,'/global/homes/b/bpb/repos/scndb/')\n",
    "import scndb.tools as wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = nx.read_graphml('CarbonNetwork.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## Export NODE class data to table\n",
    "df = G.nodes(data=True)\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = ['node','data']\n",
    "df['data'] = df['data'].apply(lambda x: dict(x))\n",
    "df = pd.concat([df.drop(['data'], axis=1), df['data'].apply(pd.Series)], axis=1)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "cols = [ 'name_identity','inchi_key_identity', 'smiles_identity', 'formula_identity', 'class', 'superclass', 'subclass', 'consensus_class']\n",
    "df = df[cols]\n",
    "df = df[pd.notna(df['inchi_key_identity'])]\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.sort_values('subclass',inplace=True)\n",
    "cols = ['class', 'superclass', 'subclass','consensus_class']\n",
    "df[cols].drop_duplicates().to_csv('non-redundant_classes.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'https://npclassifier.gnps2.org/classify?smiles='\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "out = []\n",
    "for smiles in df['smiles_identity']:\n",
    "    # smiles = df.loc[0,'smiles_identity']\n",
    "    r = requests.get('%s%s'%(url,smiles))\n",
    "    if r.status_code == 200:\n",
    "        out.append(r.json())\n",
    "    else:\n",
    "        out.append({'class_results': None,\n",
    "                     'superclass_results': None,\n",
    "                     'pathway_results': None,\n",
    "                     'isglycoside': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1402, 4), (1402, 8))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = pd.DataFrame(out)\n",
    "out2.shape,df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class_results', 'superclass_results', 'pathway_results',\n",
       "       'isglycoside'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['class_results', 'superclass_results', 'pathway_results']\n",
    "for c in cols:\n",
    "    out2[c] = out2[c].apply(lambda x: ','.join(sorted(x)) if isinstance(x,list) else '')\n",
    "\n",
    "cols = ['class_results', 'superclass_results', 'pathway_results','isglycoside']\n",
    "for c in cols:\n",
    "    out2.rename(columns={c:'npclassifier: %s'%c},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "npclassifier: pathway_results\n",
       "Shikimates and Phenylpropanoids                             462\n",
       "Fatty acids                                                 304\n",
       "Terpenoids                                                  225\n",
       "Polyketides                                                 123\n",
       "Amino acids and Peptides                                     95\n",
       "                                                             63\n",
       "Alkaloids                                                    57\n",
       "Amino acids and Peptides,Shikimates and Phenylpropanoids     31\n",
       "Polyketides,Terpenoids                                       16\n",
       "Carbohydrates                                                15\n",
       "Alkaloids,Amino acids and Peptides                            3\n",
       "Polyketides,Shikimates and Phenylpropanoids                   2\n",
       "Shikimates and Phenylpropanoids,Terpenoids                    2\n",
       "Amino acids and Peptides,Polyketides                          2\n",
       "Amino acids and Peptides,Fatty acids                          1\n",
       "Alkaloids,Shikimates and Phenylpropanoids                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2['npclassifier: pathway_results'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.concat([df,out2],axis=1).to_csv('all_assignments_top_identity_matches.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['npclassifier: class_results', 'npclassifier: superclass_results',\n",
    "       'npclassifier: pathway_results', 'npclassifier: isglycoside']\n",
    "\n",
    "pd.concat([df,out2],axis=1).drop_duplicates(subset=cols).to_csv('non-redundant_npclassifier-classes.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes 11520\n",
      "edges 8739\n"
     ]
    }
   ],
   "source": [
    "from blink.utils import filter_top_k, filter_component_additive\n",
    "# filter_top_k(G,4,'rem_predicted_score')\n",
    "G_mst = nx.maximum_spanning_tree(G)\n",
    "print('nodes',len(G_mst.nodes))\n",
    "print('edges',len(G_mst.edges))\n",
    "nx.write_graphml(G,'eom-net_0p1_subclass_clusters_mst.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "G = nx.read_graphml('eom-net_0p1_subclass_clusters.graphml')\n",
    "df = G.nodes(data=True)\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = ['node','data']\n",
    "df['data'] = df['data'].apply(lambda x: dict(x))\n",
    "df = pd.concat([df.drop(['data'], axis=1), df['data'].apply(pd.Series)], axis=1)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df['consensus_class'] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "consensus_class\n",
       "                                        4873\n",
       "Fatty acids and conjugates              2134\n",
       "Terpene lactones                        1039\n",
       "Amino acids, peptides, and analogues     870\n",
       "Benzoic acids and derivatives            708\n",
       "1-benzopyrans                            372\n",
       "Eicosanoids                              286\n",
       "Flavones                                 203\n",
       "Phenylpropanoids and polyketides         201\n",
       "Chalcones and dihydrochalcones           158\n",
       "Organoheterocyclic compounds             157\n",
       "Prenol lipids                            154\n",
       "Triterpenoids                            135\n",
       "Organic acids and derivatives            127\n",
       "Steroids and steroid derivatives         103\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of occurrences of each subclass\n",
    "subclass_counts = df['subclass'].value_counts()\n",
    "\n",
    "# Get the subclasses that have at least 100 values\n",
    "large_subclasses = subclass_counts[subclass_counts >= 100].index\n",
    "\n",
    "# Set the consensus_class for large subclasses\n",
    "df.loc[df['subclass'].isin(large_subclasses), 'consensus_class'] = df.loc[df['subclass'].isin(large_subclasses), 'subclass']\n",
    "\n",
    "# Get the subclasses that have less than 100 values\n",
    "small_subclasses = subclass_counts[subclass_counts < 100].index\n",
    "\n",
    "# Set the consensus_class for small subclasses\n",
    "df.loc[df['subclass'].isin(small_subclasses), 'consensus_class'] = df.loc[df['subclass'].isin(small_subclasses), 'class']\n",
    "\n",
    "# Get the subclasses that have less than 100 values\n",
    "class_counts = df['consensus_class'].value_counts()\n",
    "small_classes = class_counts[class_counts < 100].index\n",
    "\n",
    "# Set the consensus_class for small subclasses\n",
    "df.loc[df['consensus_class'].isin(small_classes), 'consensus_class'] = df.loc[df['consensus_class'].isin(small_classes), 'superclass']\n",
    "\n",
    "df = df[['node','consensus_class']]\n",
    "\n",
    "df.loc[df['consensus_class'].map(df['consensus_class'].value_counts()) < 100, 'consensus_class'] = None\n",
    "\n",
    "df.fillna('',inplace=True)\n",
    "df.value_counts('consensus_class')\n",
    "nx.set_node_attributes(G, df.set_index('node')['consensus_class'].to_dict(), 'consensus_class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.maximum_spanning_tree(G)\n",
    "nx.write_graphml(G, 'graph_with_consensus_class.graphml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_weights = {}\n",
    "\n",
    "for node in G.nodes:\n",
    "    weights = [data['rem_predicted_score'] for _, _, data in G.edges(node, data=True)]\n",
    "    if weights:\n",
    "        max_weights[node] = max(weights)\n",
    "    else:\n",
    "        max_weights[node] = None  # or some other value indicating no connections\n",
    "\n",
    "weights = [v for k,v in max_weights.items() if v is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "# ax.hist(weights,bins=100)\n",
    "ax.hist(weights, bins=100, density=True, histtype=\"step\",\n",
    "                               cumulative=True, label=\"Cumulative histogram\")\n",
    "# ax.set_xlim(0)\n",
    "# ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# G = nx.read_graphml('eom-net_0p1_subclass_clusters_mst.graphml')\n",
    "\n",
    "# pos = nx.nx_agraph.graphviz_layout(G, prog='neato')\n",
    "\n",
    "# nx.draw(G, pos, with_labels=False, font_weight='bold', node_color='lightblue', node_size=30)\n",
    "# plt.title(\"Nodes associated with a structural cluster\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get identity hits smiles for all nodes\n",
    "identity_smiles = nx.get_node_attributes(G, smiles_col)\n",
    "nodes_with_hits = list(identity_smiles.keys())\n",
    "\n",
    "# Get all node pairs within distance\n",
    "neighbor_distance_matrix = distance_matrix <= max_node_distance\n",
    "rows, cols = neighbor_distance_matrix.nonzero()\n",
    "neighbor_pairs = np.array([rows, cols]).T\n",
    "\n",
    "# # Define a function to compute jaccard bonds\n",
    "# def compute_jaccard_bonds_parallel(args):\n",
    "#     pair, nodes, nodes_with_hits, identity_smiles = args\n",
    "#     node0 = nodes[pair[0]]\n",
    "#     node1 = nodes[pair[1]]\n",
    "    \n",
    "#     if node0 not in nodes_with_hits or node1 not in nodes_with_hits:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         smiles0 = identity_smiles[node0]\n",
    "#         smiles1 = identity_smiles[node1]\n",
    "        \n",
    "#         return compute_jaccard_bonds(smiles0, smiles1)\n",
    "# neighbor_pairs[:3,:],nodes[:3],identity_smiles['0.0']\n",
    "smiles_pairs = [(identity_smiles[nodes[pair[0]]],identity_smiles[nodes[pair[1]]],pair[0],pair[1]) for pair in neighbor_pairs]\n",
    "smiles_pairs = [(smiles1, smiles2,pair0,pair1) for smiles1, smiles2, pair0,pair1 in smiles_pairs if isinstance(smiles1, str) and isinstance(smiles2, str)]\n",
    "# compute_jaccard_bonds(smiles_pairs[0])\n",
    "# results = []\n",
    "# for i in smiles_pairs[:3000]:\n",
    "    # results.append(compute_jaccard_bonds(i))\n",
    "\n",
    "# with Pool(20) as pool:\n",
    "#     mcs_results = pool.map(compute_jaccard_bonds, smiles_pairs[:1000])\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    mcs_results = list(executor.map(compute_jaccard_bonds, smiles_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# nonzero_jaccard_len = len([jaccard_bonds for jaccard_bonds in neighbor_jaccard_bonds if jaccard_bonds is not None])\n",
    "# print(nonzero_jaccard_len)\n",
    "min_mcs_difference\n",
    "from scipy.cluster import hierarchy\n",
    "import matplotlib.pyplot as plt\n",
    "min_mcs_difference = 0.4\n",
    "\n",
    "row_indices = [pair[2] for pair in smiles_pairs]\n",
    "col_indices = [pair[3] for pair in smiles_pairs]\n",
    "\n",
    "x = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "x[row_indices,col_indices] = mcs_results\n",
    "y = x[np.triu_indices(x.shape[0],1)]\n",
    "y = 1 - y\n",
    "\n",
    "# fig,ax = plt.subplots()\n",
    "# dn1 = hierarchy.dendrogram(Z,ax=ax)\n",
    "Z = hierarchy.linkage(y, method='single')\n",
    "\n",
    "clusters = hierarchy.fcluster(Z, t=min_mcs_difference, criterion='distance')\n",
    "\n",
    "# Add cluster labels to graph\n",
    "cluster_dict = dict(zip(nodes, clusters))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_structural_cluster_number')\n",
    "# len(clusters),len(set(clusters))\n",
    "\n",
    "cluster_counts = np.bincount(clusters)\n",
    "print(len(clusters),len(set(clusters)),len(set(clusters[np.in1d(clusters,np.where(cluster_counts>1))])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "original_index = nx.get_node_attributes(G, 'original_index')\n",
    "mcs_structural_cluster_number = nx.get_node_attributes(G, 'mcs_structural_cluster_number')\n",
    "smiles = nx.get_node_attributes(G,smiles_col)\n",
    "node_id = {k:k for k in G.nodes()}\n",
    "\n",
    "df = pd.DataFrame({'node_id':node_id,'smiles':smiles,'original_index': original_index, 'mcs_structural_cluster_number': mcs_structural_cluster_number})\n",
    "df = df[pd.notna(df['smiles'])]\n",
    "df = df.groupby('mcs_structural_cluster_number').filter(lambda x: len(x) >= 2)\n",
    "df.sort_values('mcs_structural_cluster_number', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "dfs = [d for _,d in df.groupby('mcs_structural_cluster_number')]\n",
    "out = []\n",
    "for i,dd in enumerate(dfs):\n",
    "    nodes = dd['node_id'].tolist()\n",
    "    new_nodes = min_additional_subgraph(G, nodes)\n",
    "    mols = [MolFromSmiles(s) for s in dd['smiles'].tolist()]\n",
    "    res = rdFMCS.FindMCS(mols,timeout=120,ringMatchesRingOnly=True,threshold=0.8)\n",
    "    num_bonds = [m.GetNumBonds() for m in mols]\n",
    "    mcs = res.numBonds / np.min(num_bonds)\n",
    "    # len(n),dd.shape[0],n,sorted(dd['node_id'].tolist())\n",
    "    # dd['new_nodes'] = None\n",
    "    temp = pd.DataFrame()\n",
    "    temp['node_id'] = new_nodes \n",
    "    temp = pd.merge(temp,dd,on='node_id',how='outer')\n",
    "    temp['mcs'] = mcs\n",
    "    temp['mcs_structural_cluster_number'] = i\n",
    "    temp['structural_pattern'] = res.smartsString\n",
    "    temp['mols'] = [mols for _ in range(temp.shape[0])]\n",
    "    # temp['mcs_structural_cluster_number'] = i\n",
    "    temp.drop(columns=['original_index'])\n",
    "    out.append(temp)\n",
    "\n",
    "\n",
    "df = pd.concat(out)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "df_mol_cluster = df[['mcs_structural_cluster_number','structural_pattern','mols','mcs']].copy()\n",
    "\n",
    "df_mol_cluster.drop_duplicates('mcs_structural_cluster_number',inplace=True)\n",
    "df_mol_cluster.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df_mol_cluster['num_mols']= df_mol_cluster['mols'].apply(lambda x: len(x))\n",
    "\n",
    "df_mol_cluster.sort_values('num_mols',inplace=True)\n",
    "\n",
    "df_mol_cluster.reset_index(drop=True,inplace=True)\n",
    "# p = df_mol_cluster.loc[0,'structural_pattern']\n",
    "# mol = Chem.MolFromSmarts(p)\n",
    "# s = Chem.MolToSmiles(mol)\n",
    "# mol = Chem.MolFromSmiles(s)\n",
    "# mol\n",
    "df_mol_cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pats = [Chem.MolToSmiles(Chem.MolFromSmarts(p)) for p in df_mol_cluster['structural_pattern'].tolist()]\n",
    "mcs_results = []\n",
    "for i,p1 in enumerate(pats):\n",
    "    print(i)\n",
    "    for j,p2 in enumerate(pats):\n",
    "        if i > j:\n",
    "            if (p1 is not None) & (p2 is not None):\n",
    "                try:\n",
    "                    mcs = compute_jaccard_bonds((p1, p2))\n",
    "                except ValueError as e:\n",
    "                    if str(e) == \"molecule is None\":\n",
    "                        mcs = 0\n",
    "                    else:\n",
    "                        raise e\n",
    "            else:\n",
    "                mcs = 0\n",
    "            mcs_results.append({'pat_1':i,'pat_2':j,'mcs':mcs})\n",
    "            # print(p1,p2,Chem.MolFromSmiles(p1).HasSubstructMatch(Chem.MolFromSmiles(p2)))\n",
    "mcs_results = pd.DataFrame(mcs_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "x = mcs_results.pivot(index='pat_1',columns='pat_2',values='mcs')\n",
    "x = x.values\n",
    "# x = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "# x[row_indices,col_indices] = mcs_results\n",
    "y = x[np.tril_indices(x.shape[0],0)]\n",
    "y = 1 - y\n",
    "\n",
    "Z = hierarchy.linkage(y, method='ward')\n",
    "clusters = hierarchy.fcluster(Z, t=4, criterion='maxclust')\n",
    "\n",
    "\n",
    "# # Add cluster labels to graph\n",
    "# cluster_dict = dict(zip(nodes, clusters))\n",
    "# nx.set_node_attributes(G, cluster_dict, 'mcs_structural_cluster_number')\n",
    "# # len(clusters),len(set(clusters))\n",
    "\n",
    "# cluster_counts = np.bincount(clusters)\n",
    "# print(len(clusters),len(set(clusters)),len(set(clusters[np.in1d(clusters,np.where(cluster_counts>1))])))\n",
    "df_mol_cluster['mcs_higher_cluster'] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import json\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def get_most_common(classes):\n",
    "    class_counts = Counter(classes)\n",
    "    # Get the most common string\n",
    "    most_common_class = class_counts.most_common(1)[0][0]\n",
    "    return most_common_class\n",
    "\n",
    "classyfire_dir = '/global/cfs/cdirs/metatlas/projects/classyfire_annotations/'\n",
    "superclass_name = []\n",
    "class_name = []\n",
    "for i,row in df_mol_cluster.iterrows():\n",
    "    superclasses = []\n",
    "    classes = []\n",
    "    for m in row['mols']:\n",
    "        f = '%s.json'%Chem.MolToInchiKey(m)\n",
    "        f = os.path.join(classyfire_dir,f)\n",
    "        with open(f,'r') as fid:\n",
    "            cf = fid.read()\n",
    "        cf = json.loads(cf.strip())\n",
    "        if isinstance(cf,str):\n",
    "            cf = json.loads(cf)\n",
    "        # cf_json = json.dumps(cf)\n",
    "        if not 'superclass' in cf:\n",
    "            cf['superclass'] = {'name':None}\n",
    "            cf['class'] = {'name':None}\n",
    "        superclasses.append(cf['superclass']['name'])\n",
    "        classes.append(cf['class']['name'])\n",
    "    # Count the occurrences of each string in the classes list\n",
    "    classes = [c for c in classes if c is not None]\n",
    "    superclasses = [c for c in superclasses if c is not None]\n",
    "    if len(classes) == 0:\n",
    "        class_name.append(None)\n",
    "        superclass_name.append(None)\n",
    "    else:    \n",
    "        # Print the most common class\n",
    "        class_name.append(get_most_common(classes))\n",
    "        superclass_name.append(get_most_common(superclasses))\n",
    "df_mol_cluster['superclass'] = superclass_name\n",
    "df_mol_cluster['class'] = class_name\n",
    "df_mol_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mol_cluster.value_counts('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "outdir = '/global/homes/b/bpb/repos/scndb/data/struct_clusters_quartered'\n",
    "if os.path.exists(outdir):\n",
    "    shutil.rmtree(outdir)\n",
    "    # os.rmdir(outdir)\n",
    "os.makedirs(outdir)\n",
    "\n",
    "\n",
    "dfs = [d for _,d in df_mol_cluster.groupby('mcs_higher_cluster')]\n",
    "for dd in dfs:\n",
    "    mol_list = []\n",
    "    my_legend = []\n",
    "    for i,row in dd.iterrows():\n",
    "        mol_list.extend(row['mols'])\n",
    "        my_legend.extend(['%d'%row['mcs_structural_cluster_number'] for _ in range(len(row['mols']))])\n",
    "    \n",
    "    # Smarts pattern for common substructure\n",
    "    pat = MolFromSmarts(dd['structural_pattern'].tolist()[0])\n",
    "\n",
    "    image = MolsToGridImage(mol_list, molsPerRow=20, subImgSize=(300, 300), useSVG=True,maxMols=1000,legends=my_legend)\n",
    "                            #  highlightAtomLists=highlist_list,highlightAtomColors=[highlight_color]*len(mols))\n",
    "\n",
    "    # Display the image\n",
    "    outfile = os.path.join(outdir,'{}.svg'.format(dd['mcs_higher_cluster'].tolist()[0]))\n",
    "    with open(outfile,'w') as fid:\n",
    "        fid.write(image.data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# original_index = nx.get_node_attributes(G, 'original_index')\n",
    "# mcs_structural_cluster_number = nx.get_node_attributes(G, 'mcs_structural_cluster_number')\n",
    "# smiles = nx.get_node_attributes(G,smiles_col)\n",
    "\n",
    "# df = pd.DataFrame({'smiles':smiles,'original_index': original_index, 'mcs_structural_cluster_number': mcs_structural_cluster_number})\n",
    "# df = df[pd.notna(df['smiles'])]\n",
    "# df = df.groupby('mcs_structural_cluster_number').filter(lambda x: len(x) >= 2)\n",
    "# df.sort_values('mcs_structural_cluster_number', inplace=True)\n",
    "# df = df[df['mcs_structural_cluster_number']>0]\n",
    "# my_list = [MolFromSmiles(m) for m in df['smiles'].values]\n",
    "# my_legend = ['%d'%m for m in df['mcs_structural_cluster_number'].values]\n",
    "# image = MolsToGridImage(my_list, molsPerRow=10,maxMols=1000,legends=my_legend,useSVG=True)\n",
    "\n",
    "# outfile = os.path.join(outdir,'AllStructuralClusters_massive.svg')\n",
    "# with open(outfile,'w') as fid:\n",
    "#     fid.write(image.data)\n",
    "\n",
    "\n",
    "# shutil.make_archive('../data/structural_clusters_massive', 'zip', '.', outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n",
    "\n",
    "\n",
    "node_id = {k:k for k in G.nodes()}\n",
    "node_id = pd.Series(node_id)\n",
    "node_id = node_id.to_frame()\n",
    "node_id.columns = ['node_id']\n",
    "node_id = pd.merge(node_id,df,on='node_id',how='left')\n",
    "# node_id = node_id[['node_id','structural_pattern','mcs','mcs_structural_cluster_number']]\n",
    "node_id['structural_pattern'] = node_id['structural_pattern'].fillna('')\n",
    "node_id['mcs'] = node_id['mcs'].fillna(0)\n",
    "node_id['mcs_structural_cluster_number'] = node_id['mcs_structural_cluster_number'].fillna(-1)\n",
    "node_id['mcs_structural_cluster_number'] = node_id['mcs_structural_cluster_number'].astype(int)\n",
    "node_id['structural_pattern'] = node_id['structural_pattern'].astype(str)\n",
    "node_id['mcs'] = node_id['mcs'].astype(float)\n",
    "node_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add cluster labels to graph\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['structural_pattern'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_structural_pattern')\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['mcs'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_similarity')\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['mcs_structural_cluster_number'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_structural_cluster_number')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(G, 'eom-net-0p01-all-clust.graphml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "outdir = '/global/homes/b/bpb/repos/scndb/data/struct_clusters_al-v2'\n",
    "if os.path.exists(outdir):\n",
    "    shutil.rmtree(outdir)\n",
    "    # os.rmdir(outdir)\n",
    "os.makedirs(outdir)\n",
    "\n",
    "\n",
    "dfs = [d for _,d in df[df['mcs_structural_cluster_number']>0].groupby('mcs_structural_cluster_number')]\n",
    "for dd in dfs:\n",
    "    dd = dd[pd.notna(dd['smiles'])]\n",
    "    # List of smiles\n",
    "    smiles_list = dd['smiles'].tolist()\n",
    "\n",
    "    # Smarts pattern for common substructure\n",
    "    pat = MolFromSmarts(dd['structural_pattern'].tolist()[0])\n",
    "\n",
    "    # Convert smiles to RDKit molecules\n",
    "    mols = [MolFromSmiles(smiles) for smiles in smiles_list]\n",
    "\n",
    "    highlight_list = [mol.GetSubstructMatch(pat) for mol in mols]\n",
    "    my_legend = ['%d'%m for m in dd['mcs_structural_cluster_number'].values]\n",
    "    highlist_list = highlight_list\n",
    "    \n",
    "    # [mol.GetSubstructMatch(pat) for mol in mols]\n",
    "    # Generate common substructure image\n",
    "    highlight_color = {i: (0, 1, 1) for mol in mols for i in mol.GetSubstructMatch(pat)}\n",
    "    image = MolsToGridImage(mols, molsPerRow=5, subImgSize=(300, 300), useSVG=True,maxMols=1000,\n",
    "                            legends=my_legend, highlightAtomLists=highlist_list,highlightAtomColors=[highlight_color]*len(mols))\n",
    "\n",
    "    # Display the image\n",
    "    outfile = os.path.join(outdir,'{}.svg'.format(dd['mcs_structural_cluster_number'].tolist()[0]))\n",
    "    with open(outfile,'w') as fid:\n",
    "        fid.write(image.data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "original_index = nx.get_node_attributes(G, 'original_index')\n",
    "mcs_structural_cluster_number = nx.get_node_attributes(G, 'mcs_structural_cluster_number')\n",
    "smiles = nx.get_node_attributes(G,smiles_col)\n",
    "\n",
    "df = pd.DataFrame({'smiles':smiles,'original_index': original_index, 'mcs_structural_cluster_number': mcs_structural_cluster_number})\n",
    "df = df[pd.notna(df['smiles'])]\n",
    "df = df.groupby('mcs_structural_cluster_number').filter(lambda x: len(x) >= 2)\n",
    "df.sort_values('mcs_structural_cluster_number', inplace=True)\n",
    "df = df[df['mcs_structural_cluster_number']>0]\n",
    "my_list = [MolFromSmiles(m) for m in df['smiles'].values]\n",
    "my_legend = ['%d'%m for m in df['mcs_structural_cluster_number'].values]\n",
    "image = MolsToGridImage(my_list, molsPerRow=10,maxMols=1000,legends=my_legend,useSVG=True)\n",
    "\n",
    "outfile = os.path.join(outdir,'AllStructuralClusters_massive.svg')\n",
    "with open(outfile,'w') as fid:\n",
    "    fid.write(image.data)\n",
    "\n",
    "\n",
    "shutil.make_archive('../data/structural_clusters_massive', 'zip', '.', outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "original_index = nx.get_node_attributes(G, 'original_index')\n",
    "mcs_structural_cluster_number = nx.get_node_attributes(G, 'mcs_structural_cluster_number')\n",
    "smiles = nx.get_node_attributes(G,smiles_col)\n",
    "node_id = {k:k for k in G.nodes()}\n",
    "\n",
    "df = pd.DataFrame({'node_id':node_id,'smiles':smiles,'original_index': original_index, 'mcs_structural_cluster_number': mcs_structural_cluster_number})\n",
    "df = df[pd.notna(df['smiles'])]\n",
    "df = df.groupby('mcs_structural_cluster_number').filter(lambda x: len(x) >= 2)\n",
    "df.sort_values('mcs_structural_cluster_number', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "dfs = [d for _,d in df.groupby('mcs_structural_cluster_number')]\n",
    "out = []\n",
    "for i,dd in enumerate(dfs):\n",
    "    nodes = dd['node_id'].tolist()\n",
    "    new_nodes = min_additional_subgraph(G, nodes)\n",
    "    mols = [MolFromSmiles(s) for s in dd['smiles'].tolist()]\n",
    "    res = rdFMCS.FindMCS(mols,timeout=120,ringMatchesRingOnly=True)\n",
    "    num_bonds = [m.GetNumBonds() for m in mols]\n",
    "    mcs = res.numBonds / np.min(num_bonds)\n",
    "    # len(n),dd.shape[0],n,sorted(dd['node_id'].tolist())\n",
    "    # dd['new_nodes'] = None\n",
    "    temp = pd.DataFrame()\n",
    "    temp['node_id'] = new_nodes \n",
    "    temp = pd.merge(temp,dd,on='node_id',how='outer')\n",
    "    temp['mcs'] = mcs\n",
    "    temp['mcs_structural_cluster_number'] = i\n",
    "    temp['structural_pattern'] = res.smartsString\n",
    "    # temp['mcs_structural_cluster_number'] = i\n",
    "    temp.drop(columns=['original_index'])\n",
    "    out.append(temp)\n",
    "\n",
    "\n",
    "df = pd.concat(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id = {k:k for k in G.nodes()}\n",
    "node_id = pd.Series(node_id)\n",
    "node_id = node_id.to_frame()\n",
    "node_id.columns = ['node_id']\n",
    "node_id = pd.merge(node_id,df,on='node_id',how='left')\n",
    "# node_id = node_id[['node_id','structural_pattern','mcs','mcs_structural_cluster_number']]\n",
    "node_id['structural_pattern'] = node_id['structural_pattern'].fillna('')\n",
    "node_id['mcs'] = node_id['mcs'].fillna(0)\n",
    "node_id['mcs_structural_cluster_number'] = node_id['mcs_structural_cluster_number'].fillna(-1)\n",
    "node_id['mcs_structural_cluster_number'] = node_id['mcs_structural_cluster_number'].astype(int)\n",
    "node_id['structural_pattern'] = node_id['structural_pattern'].astype(str)\n",
    "node_id['mcs'] = node_id['mcs'].astype(float)\n",
    "node_id\n",
    "\n",
    "# Add cluster labels to graph\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['structural_pattern'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_structural_pattern')\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['mcs'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_similarity')\n",
    "cluster_dict = dict(zip(node_id['node_id'].tolist(), node_id['mcs_structural_cluster_number'].tolist()))\n",
    "nx.set_node_attributes(G, cluster_dict, 'mcs_structural_cluster_number')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat(out)\n",
    "df['nl_spectrum'] = df.apply(lambda x: np.asarray([x['mdm_mz_vals'],x['mdm_i_vals']]),axis=1)\n",
    "\n",
    "df['sum_frag_intensity'] = df['mdm_i_vals'].apply(lambda x: np.sum(x))\n",
    "df['original_spectrum'] = df['nl_spectrum']#df.apply(lambda x: np.asarray([x['original_mz_vals'],x['original_i_vals']]),axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_files = merged_df.loc[merged_df['percent_greater'] < 40,'filename'].tolist()\n",
    "# print(df.shape[0])\n",
    "# df = df[df['filename'].isin(good_files)]\n",
    "# print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coisolated_precursor_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sum_frag_intensity']>0]\n",
    "df['num_mdm_frags'] = df['mdm_mz_vals'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_mdm_frags'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref,ref2 = wt.get_p2d2(deltas,mz_tol=mz_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dfs = wt.blink_score(df,ref,ref2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['rem_predicted_score','ref','query']\n",
    "nl_hits = pd.merge(out_dfs[3][cols],ref2[['original_p2d2_index']],left_on='ref',right_index=True)\n",
    "orig_hits = pd.merge(out_dfs[2][cols],ref[['original_p2d2_index']],left_on='ref',right_index=True)\n",
    "nl_hits.drop(columns=['ref'],inplace=True)\n",
    "orig_hits.drop(columns=['ref'],inplace=True)\n",
    "\n",
    "temp = pd.merge(nl_hits,orig_hits,on=['query','original_p2d2_index'],how='outer',suffixes=('_original_rem','_nl_rem'))\n",
    "\n",
    "temp['max_score'] = temp[['rem_predicted_score_original_rem','rem_predicted_score_nl_rem']].max(axis=1)\n",
    "temp['best_match_method'] = temp[['rem_predicted_score_original_rem','rem_predicted_score_nl_rem']].idxmax(axis=1)\n",
    "temp.sort_values('max_score',ascending=False,inplace=True)\n",
    "temp = temp[temp['max_score']>0.01]  #filter on score\n",
    "\n",
    "cols = ['name', 'inchi_key', 'smiles']\n",
    "\n",
    "temp = pd.merge(temp,df[['original_index','coisolated_precursor_count']].add_suffix('_query'),left_on='query',right_index=True)\n",
    "\n",
    "idx_isolated = (temp['coisolated_precursor_count_query']>1) & (temp['best_match_method']=='rem_predicted_score_original_rem')\n",
    "temp = temp[~idx_isolated] #filter on co-isolated precursor\n",
    "\n",
    "temp.sort_values('max_score',ascending=False,inplace=True)\n",
    "temp = temp.groupby('query').head(1)\n",
    "temp.reset_index(inplace=True,drop=True)\n",
    "\n",
    "cols = ['rem_predicted_score_original_rem', 'rem_predicted_score_nl_rem', 'coisolated_precursor_count_query']\n",
    "temp.drop(columns=cols,inplace=True)\n",
    "\n",
    "cols = ['name', 'inchi_key', 'smiles','formula','precursor_mz','original_p2d2_index']\n",
    "temp = pd.merge(temp,ref[cols],left_on='original_p2d2_index',right_on='original_p2d2_index',how='left')\n",
    "\n",
    "df = pd.merge(df,temp.add_suffix('_analog'),left_on='original_index',right_on='original_index_query_analog',how='left')\n",
    "# df.drop(columns=['original_index_query_analog','original_p2d2_index','query'],inplace=True)\n",
    "\n",
    "cols = ['original_index_query_analog','query_analog']\n",
    "df.drop(columns=cols,inplace=True)\n",
    "\n",
    "\n",
    "cols = ['score','matches','ref','query']\n",
    "nl_hits = pd.merge(out_dfs[1][cols],ref2[['original_p2d2_index']],left_on='ref',right_index=True)\n",
    "orig_hits = pd.merge(out_dfs[0][cols],ref[['original_p2d2_index']],left_on='ref',right_index=True)\n",
    "nl_hits.drop(columns=['ref'],inplace=True)\n",
    "orig_hits.drop(columns=['ref'],inplace=True)\n",
    "\n",
    "temp = pd.merge(nl_hits,orig_hits,on=['query','original_p2d2_index'],how='outer',suffixes=('_original','_nl'))\n",
    "\n",
    "temp['max_score'] = temp[['score_original','score_nl']].max(axis=1)\n",
    "temp['best_match_method'] = temp[['score_original','score_nl']].idxmax(axis=1)\n",
    "temp.sort_values('max_score',ascending=False,inplace=True)\n",
    "temp = temp[temp['max_score']>0.7]  #filter on score\n",
    "temp['max_matches'] = 0\n",
    "idx = temp['best_match_method']=='score_original'\n",
    "temp.loc[idx,'max_matches'] = temp.loc[idx,'matches_original']\n",
    "idx = temp['best_match_method']=='score_nl'\n",
    "temp.loc[idx,'max_matches'] = temp.loc[idx,'matches_nl']\n",
    "temp = temp[temp['max_matches']>=3]  #filter on matches\n",
    "\n",
    "cols = ['score_original','matches_original', 'score_nl', 'matches_nl']\n",
    "temp.drop(columns=cols,inplace=True)\n",
    "temp = pd.merge(temp,df[['original_index','precursor_mz','coisolated_precursor_count']].add_suffix('_query'),left_on='query',right_index=True)\n",
    "\n",
    "idx_isolated = (temp['coisolated_precursor_count_query']>1) & (temp['best_match_method']=='score_original')\n",
    "temp = temp[~idx_isolated] #filter on isolated precursor\n",
    "\n",
    "cols = ['name', 'inchi_key', 'smiles','formula','precursor_mz','original_p2d2_index']\n",
    "temp = pd.merge(temp,ref[cols],left_on='original_p2d2_index',right_on='original_p2d2_index',how='left')\n",
    "\n",
    "idx_precursor = (abs(temp['precursor_mz_query']-temp['precursor_mz'])<mz_tol)\n",
    "temp = temp[idx_precursor] #filter on precursor m/z\n",
    "\n",
    "temp.sort_values('max_score',ascending=False,inplace=True)\n",
    "\n",
    "temp = temp.groupby('query').head(1)\n",
    "temp.reset_index(inplace=True,drop=True)\n",
    "\n",
    "df = pd.merge(df,temp.add_suffix('_identity'),left_on='original_index',right_on='original_index_query_identity',how='left')\n",
    "# df.drop(columns=['original_index_query_analog','original_p2d2_index','query'],inplace=True)\n",
    "\n",
    "cols = ['original_index_query_identity',\n",
    "        'query_identity',\n",
    "        'precursor_mz_query_identity',\n",
    "        'coisolated_precursor_count_query_identity']\n",
    "df.drop(columns=cols,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['original_p2d2_index_analog','nl_spectrum']\n",
    "# cols = ['original_p2d2_index_identity','nl_spectrum']\n",
    "# cols = ['original_p2d2_index_analog','spectrum']\n",
    "cols = ['original_p2d2_index','spectrum']\n",
    "df = pd.merge(df,ref[cols].add_suffix('_ref_identity'),left_on='original_p2d2_index_identity',right_on='original_p2d2_index_ref_identity',how='left')\n",
    "df = pd.merge(df,ref[cols].add_suffix('_ref_analog'),left_on='original_p2d2_index_analog',right_on='original_p2d2_index_ref_analog',how='left')\n",
    "drop = ['original_p2d2_index_ref_identity','original_p2d2_index_ref_analog']\n",
    "df.drop(columns=drop,inplace=True)\n",
    "cols = ['original_p2d2_index','nl_spectrum']\n",
    "df = pd.merge(df,ref2[cols].add_suffix('_ref_identity'),left_on='original_p2d2_index_identity',right_on='original_p2d2_index_ref_identity',how='left')\n",
    "df = pd.merge(df,ref2[cols].add_suffix('_ref_analog'),left_on='original_p2d2_index_analog',right_on='original_p2d2_index_ref_analog',how='left')\n",
    "drop = ['original_p2d2_index_ref_identity','original_p2d2_index_ref_analog']\n",
    "df.drop(columns=drop,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df['predicted_formula'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values('num_mdm_frags',ascending=False,inplace=True)\n",
    "# df.drop_duplicates('predicted_formula',inplace=True)\n",
    "# df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[pd.notna(df['predicted_formula'])]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wt.eliminate_duplicate_spectra(out,deltas,mz_tol=mz_tol,\n",
    "                                similarity_cutoff=similarity_cutoff,\n",
    "                                min_intensity_ratio=min_intensity_ratio)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coisolated_precursor_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# rem_df = wt.do_remblink_networking(df,df,spectra_attr='buddy_spectrum')\n",
    "rem_df = wt.do_remblink_networking(df,df,spectra_attr='nl_spectrum')\n",
    "cols = ['ref','query','rem_predicted_score']\n",
    "rem_df = rem_df[cols]\n",
    "rem_df = rem_df[rem_df['rem_predicted_score']>0.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_props = wt.get_formula_props(df,formula_key='predicted_formula')\n",
    "df = pd.merge(df,formula_props,left_on='predicted_formula',right_on='formula',how='left')\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = pd.read_parquet('/global/cfs/cdirs/metatlas/projects/rawdata_for_scn/20181217_KBL_TM_Lakes_GEODES_All3_QE-HF_C18_USDAY46918_NEG_MSMS_68_GEO-TB-36-F_1_Rg80to1200-CE102040-0-1-S1_Run246.parquet')\n",
    "# p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOM net: (6283, 13884)\n",
    "# Plant net: (3424, 4873)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# # Create the graph from the similarity matrix\n",
    "G = nx.from_pandas_edgelist(rem_df,source='ref',target='query',edge_attr='rem_predicted_score')\n",
    "# (similarity_matrix > similarity_cutoff)\n",
    "# # Add node data from ms2_df to G\n",
    "cols = list(set([c for c in df.columns if not 'spect' in c]) - set(['obs','coisolated_precursor_mz_list','mol','filename', 'basename', 'experiment']))\n",
    "cols = [c for c in cols if not 'mdm_' in c]\n",
    "cols = [c for c in cols if not 'original_' in c]\n",
    "# cols = cols + ['stable']\n",
    "node_data = df[cols].to_dict(orient='index')\n",
    "\n",
    "nx.set_node_attributes(G, node_data)\n",
    "            \n",
    "# print(len(G.nodes))\n",
    "# print(len(G.edges))\n",
    "\n",
    "# # Remove self-loops\n",
    "G.remove_edges_from([(u, v) for u, v in G.edges() if u == v])         \n",
    "\n",
    "# Remove isolates\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "print('nodes',len(G.nodes))\n",
    "print('edges',len(G.edges))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "250000**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_sum_frag_intensity'] = np.log10(df['sum_frag_intensity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = (df['isin_fticr_formula'] == True) & (df['predicted_formula'].str.contains('S'))\n",
    "idx2 = (df['isin_fticr_formula'] == False) & (df['predicted_formula'].str.contains('S'))\n",
    "out = []\n",
    "out.append((sum(idx1),sum(idx2),sum(idx1)+sum(idx2)))\n",
    "\n",
    "idx1 = (df['isin_fticr_formula'] == True) & (df['predicted_formula'].str.contains('N'))\n",
    "idx2 = (df['isin_fticr_formula'] == False) & (df['predicted_formula'].str.contains('N'))\n",
    "\n",
    "out.append((sum(idx1),sum(idx2),sum(idx1)+sum(idx2)))\n",
    "\n",
    "idx1 = (df['isin_fticr_formula'] == True) & (df['predicted_formula'].str.contains('P'))\n",
    "idx2 = (df['isin_fticr_formula'] == False) & (df['predicted_formula'].str.contains('P'))\n",
    "\n",
    "out.append((sum(idx1),sum(idx2),sum(idx1)+sum(idx2)))\n",
    "\n",
    "idx1 = (df['isin_fticr_formula'] == True) & (~df['predicted_formula'].str.contains('P|N|S'))\n",
    "idx2 = (df['isin_fticr_formula'] == False) & (~df['predicted_formula'].str.contains('P|N|S'))\n",
    "\n",
    "out.append((sum(idx1),sum(idx2),sum(idx1)+sum(idx2)))\n",
    "out = pd.DataFrame(out,columns=['FTICR','Not FTICR','Total'],index=['S','N','P','CHO'])\n",
    "out['FTICR'] = out['FTICR'] / out['Total']\n",
    "out['Not FTICR'] = out['Not FTICR'] / out['Total']\n",
    "out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = df.dtypes\n",
    "print(column_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ARE WE MISSING ANY FTICR FORMULA??????\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2,ncols=2,figsize=(10,6 ))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Filter rows where isin_fticr_formula is True\n",
    "df_true = df[df['isin_fticr_formula']]\n",
    "\n",
    "# Filter rows where isin_fticr_formula is False\n",
    "df_false = df[~df['isin_fticr_formula']]\n",
    "\n",
    "# Plot histogram for isin_fticr_formula=True\n",
    "counter = 0\n",
    "df['log_sum_frag_intensity'] = np.log10(df['sum_frag_intensity'])\n",
    "cols = ['coisolated_precursor_count', 'num_mdm_frags','mass_error','log_sum_frag_intensity']\n",
    "for c in cols:\n",
    "    ax[counter].hist(df_true[c], bins=15, alpha=0.5, density=False,label='isin_fticr_formula=True')\n",
    "\n",
    "    # Plot histogram for isin_fticr_formula=False\n",
    "    ax[counter].hist(df_false[c], bins=15, alpha=0.5,density=False, label='isin_fticr_formula=False')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax[counter].set_xlabel(c)\n",
    "    ax[counter].set_ylabel('Frequency')\n",
    "    ax[counter].legend()\n",
    "    counter += 1\n",
    "plt.tight_layout()\n",
    "# ax.set_xlim(-0.001,0.001)\n",
    "# Add legend\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['environment_type:aquatic', 'environment_type:soil',\n",
    "       'environment_type:wetland', 'extraction_solvent:chloroform',\n",
    "       'extraction_solvent:methanol-water', 'extraction_solvent:water',\n",
    "       'ppl_extracted:False', 'ppl_extracted:True',\n",
    "       'instrument_type:12 Tesla FT-ICR-MS',\n",
    "       'instrument_type:15 Tesla FT-ICR-MS', 'mass_range:100-900',\n",
    "       'mass_range:125-2000', 'mass_range:150-2000', 'mass_range:200-1200']\n",
    "formula_df.loc[~formula_df['formula'].isin(df['predicted_formula']),cols].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_complex_attributes(G):\n",
    "    for node, data in G.nodes(data=True):\n",
    "        complex_attributes = [key for key, value in data.items() if isinstance(value, (list, set, dict,object))]\n",
    "        for attribute in complex_attributes:\n",
    "            del G.nodes[node][attribute]\n",
    "    return G\n",
    "G = remove_complex_attributes(G) #it removes everything.\n",
    "nx.write_graphml(G, 'eom-net-0p1-cutoff-cho.graphml')\n",
    "# nx.write_graphml(G, 'plantmasst_0p1.graphml')\n",
    "# 250000**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['buddy'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msbuddy",
   "language": "python",
   "name": "msbuddy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
